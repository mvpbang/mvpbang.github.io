<!doctype html><html lang=zh-hans><head><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1"><meta name=referrer content="no-referrer-when-downgrade"><title>(3)sealos-v3多master高可用部署 | mvpbang</title>
<meta property="og:title" content="(3)sealos-v3多master高可用部署 - mvpbang"><meta property="og:type" content="article"><meta property="article:published_time" content='2022-09-12T15:48:04+08:00'><meta property="article:modified_time" content='2022-09-12T15:48:04+08:00'><meta name=Keywords content="golang,python,shell,devops,kubernetes,cicd,system,sre"><meta name=description content="(3)sealos-v3多master高可用部署"><meta name=author content="mvpbang"><meta property="og:url" content="https://blog.mvpbang.com/2022/09/3sealos-v3%E5%A4%9Amaster%E9%AB%98%E5%8F%AF%E7%94%A8%E9%83%A8%E7%BD%B2/"><link rel="shortcut icon" href=/favicon.ico type=image/x-icon><link rel=stylesheet href=/css/normalize.css><link rel=stylesheet href=/css/style.css><script type=text/javascript src=//cdn.bootcdn.net/ajax/libs/jquery/3.4.1/jquery.min.js></script><link rel=stylesheet href=/css/douban.css><link rel=stylesheet href=/css/other.css></head><body><header id=header class=clearfix><div class=container><div class=col-group><div class=site-name><a id=logo href=https://blog.mvpbang.com/>mvpbang</a><p class=description>专注运维相关工作：devops、kubernetes、cicd、system、sre</p></div><div><nav id=nav-menu class=clearfix><a class=current href=https://blog.mvpbang.com/>首页</a>
<a href=https://blog.mvpbang.com/archives/ title=归档>归档</a>
<a href=https://blog.mvpbang.com/tags/ title=标签>标签</a>
<a href=https://blog.mvpbang.com/about/ title=关于>关于</a></nav></div></div></div></header><div id=body><div class=container><div class=col-group><div class=col-8 id=main><div class=res-cons><style type=text/css>.post-toc{position:fixed;width:200px;margin-left:-210px;padding:5px 10px;font-family:Athelas,STHeiti,Microsoft Yahei,serif;font-size:12px;border:1px solid rgba(0,0,0,7%);border-radius:5px;background-color:rgba(255,255,255,.98);background-clip:padding-box;-webkit-box-shadow:1px 1px 2px rgba(0,0,0,.125);box-shadow:1px 1px 2px rgba(0,0,0,.125);word-wrap:break-word;white-space:nowrap;-webkit-box-sizing:border-box;box-sizing:border-box;z-index:999;cursor:pointer;max-height:70%;overflow-y:auto;overflow-x:hidden}.post-toc .post-toc-title{width:100%;margin:0 auto;font-size:20px;font-weight:400;text-transform:uppercase;text-align:center}.post-toc .post-toc-content{font-size:15px}.post-toc .post-toc-content>nav>ul{margin:10px 0}.post-toc .post-toc-content ul{padding-left:20px;list-style:square;margin:.5em;line-height:1.8em}.post-toc .post-toc-content ul ul{padding-left:15px;display:none}@media print,screen and (max-width:1057px){.post-toc{display:none}}</style><div class=post-toc style=position:absolute;top:188px><h2 class=post-toc-title>文章目录</h2><div class=post-toc-content><nav id=TableOfContents><ul><li><a href=#1sealos>1.sealos</a></li><li><a href=#2init-kube>2.init kube</a></li><li><a href=#3验证>3.验证</a></li><li><a href=#4集群节点操作>4.集群节点操作</a></li></ul></nav></div></div><script type=text/javascript>$(document).ready(function(){if(e=$(".post-toc"),e.length){t=$("#main").offset().left,t<220&&e.css({width:t-10,"margin-left":0-t});var e,t,n=e.offset().top-20,s={start:{position:"absolute",top:n},process:{position:"fixed",top:20}};$(window).scroll(function(){var t=$(window).scrollTop();t<n?e.css(s.start):e.css(s.process)})}$("#TableOfContents").children().length<1&&$(".post-toc").remove()})</script><article class=post><header><h1 class=post-title>(3)sealos-v3多master高可用部署</h1></header><time datetime=2022-09-12T07:48:04Z class="post-meta meta-date dt-published">2022年9月12日</time><div class="post-meta meta-category"><span>&nbsp;|</span>
<a href=/categories/sealos target=_blank>sealos</a></div><div class=post-meta><span id=busuanzi_container_page_pv>&nbsp;|
<span id=busuanzi_value_page_pv></span> <span>阅读</span></span></div><div class=clear style=display:none><div class=toc-article><div class=toc-title>文章目录</div></div></div><div class=post-content><p>使用sealos v3离线搭建3master kubernetes高可用集群&mldr;</p><h1 id=env>env</h1><ul><li>sealos-v3.3.9-rc.3</li><li>kube1.19.0.tar.gz</li><li>OpenCloudOS 8.6 x3 2c4g/40g</li></ul><h2 id=1sealos>1.sealos</h2><ul><li><a href=https://github.com/labring/sealos/releases/tag/v3.3.9-rc.11>https://github.com/labring/sealos/releases/tag/v3.3.9-rc.11</a></li></ul><h2 id=2init-kube>2.init kube</h2><pre tabindex=0><code># help
./sealos init -h

# init
./sealos init --user root --passwd &#39;321321&#39; \
	--master 172.24.20.51  --master 172.24.20.52  --master  172.24.20.53 \
	--pkg-url /root/kube1.19.0.tar.gz \
	--version v1.19.0

# init more self define
./sealos init --user root --passwd &#39;321321&#39; \
	--master 172.24.20.51  --master 172.24.20.52  --master  172.24.20.53 \
    --podcidr &#39;10.20.0.0/16&#39; --svccidr &#39;10.40.0.0/16&#39; --vip 10.10.10.10 \
	--pkg-url /root/kube1.19.0.tar.gz \
	--version v1.19.0

./sealos init --user root --passwd &#39;321321&#39; \
	--master 172.24.20.51  --master 172.24.20.52  --master  172.24.20.53 \
    --node 192.168.0.5 \
	--pkg-url /root/kube1.19.0.tar.gz \
	--version v1.19.0
</code></pre><p>#log</p><pre tabindex=0><code>[root@cloudos-51 ~]# ./sealos init --user root --passwd &#39;321321&#39; \
&gt; --master 172.24.20.51  --master 172.24.20.52  --master  172.24.20.53 \
&gt;     --podcidr &#39;10.20.0.0/16&#39; --svccidr &#39;10.40.0.0/16&#39; --vip 10.10.10.10 \
&gt; --pkg-url /root/kube1.19.0.tar.gz \
&gt; --version v1.19.0
06:50:47 [INFO] [ssh.go:13] [ssh][172.24.20.51:22] hostname
06:50:47 [DEBG] [ssh.go:25] [ssh][172.24.20.51:22]command result is: cloudos-51

06:50:47 [DEBG] [ssh.go:58] [172.24.20.51:22] cat /etc/hosts |grep cloudos-51 || echo &#39;172.24.20.51 cloudos-51&#39; &gt;&gt; /etc/hosts
06:50:48 [INFO] [ssh.go:51] [172.24.20.51:22] 172.24.20.51 cloudos-51
06:50:48 [INFO] [ssh.go:51] [172.24.20.51:22] 172.20.20.51 cloudos-51
06:50:48 [INFO] [check.go:51] [172.24.20.51:22]  ------------ check ok
06:50:48 [INFO] [ssh.go:13] [ssh][172.24.20.52:22] hostname
06:50:48 [DEBG] [ssh.go:25] [ssh][172.24.20.52:22]command result is: cloudos-52

06:50:48 [DEBG] [ssh.go:58] [172.24.20.52:22] cat /etc/hosts |grep cloudos-52 || echo &#39;172.24.20.52 cloudos-52&#39; &gt;&gt; /etc/hosts
06:50:48 [INFO] [ssh.go:51] [172.24.20.52:22] 172.24.20.52 cloudos-52
06:50:48 [INFO] [ssh.go:51] [172.24.20.52:22] 172.20.20.52 cloudos-52
06:50:48 [INFO] [check.go:51] [172.24.20.52:22]  ------------ check ok
06:50:48 [INFO] [ssh.go:13] [ssh][172.24.20.53:22] hostname
06:50:49 [DEBG] [ssh.go:25] [ssh][172.24.20.53:22]command result is: cloudos-53

06:50:49 [DEBG] [ssh.go:58] [172.24.20.53:22] cat /etc/hosts |grep cloudos-53 || echo &#39;172.24.20.53 cloudos-53&#39; &gt;&gt; /etc/hosts
06:50:49 [INFO] [ssh.go:51] [172.24.20.53:22] 172.24.20.53 cloudos-53
06:50:49 [INFO] [ssh.go:51] [172.24.20.53:22] 172.20.20.53 cloudos-53
06:50:49 [INFO] [check.go:51] [172.24.20.53:22]  ------------ check ok
06:50:49 [INFO] [print.go:14] 
[globals]sealos config is:  {&#34;Hosts&#34;:[&#34;172.24.20.51:22&#34;,&#34;172.24.20.52:22&#34;,&#34;172.24.20.53:22&#34;],&#34;Masters&#34;:[&#34;172.24.20.51:22&#34;,&#34;172.24.20.52:22&#34;,&#34;172.24.20.53:22&#34;],&#34;Nodes&#34;:null,&#34;Network&#34;:&#34;calico&#34;,&#34;ApiServer&#34;:&#34;apiserver.cluster.local&#34;}
06:50:49 [DEBG] [ssh.go:58] [172.24.20.53:22] mkdir -p /usr/bin || true
06:50:49 [DEBG] [ssh.go:58] [172.24.20.51:22] mkdir -p /usr/bin || true
06:50:49 [DEBG] [ssh.go:58] [172.24.20.52:22] mkdir -p /usr/bin || true
06:50:50 [DEBG] [download.go:30] [172.24.20.52:22]please wait for mkDstDir
06:50:50 [DEBG] [download.go:32] [172.24.20.52:22]please wait for before hook
06:50:50 [DEBG] [ssh.go:58] [172.24.20.52:22] ps -ef |grep -v &#39;grep&#39;|grep sealos &gt;/dev/null || rm -rf /usr/bin/sealos
06:50:50 [DEBG] [download.go:30] [172.24.20.53:22]please wait for mkDstDir
06:50:50 [DEBG] [download.go:32] [172.24.20.53:22]please wait for before hook
06:50:50 [DEBG] [ssh.go:58] [172.24.20.53:22] ps -ef |grep -v &#39;grep&#39;|grep sealos &gt;/dev/null || rm -rf /usr/bin/sealos
06:50:50 [DEBG] [download.go:30] [172.24.20.51:22]please wait for mkDstDir
06:50:50 [DEBG] [download.go:32] [172.24.20.51:22]please wait for before hook
06:50:50 [DEBG] [ssh.go:58] [172.24.20.51:22] ps -ef |grep -v &#39;grep&#39;|grep sealos &gt;/dev/null || rm -rf /usr/bin/sealos
06:50:50 [INFO] [ssh.go:13] [ssh][172.24.20.53:22] ls -l /usr/bin/sealos 2&gt;/dev/null |wc -l
06:50:50 [INFO] [ssh.go:13] [ssh][172.24.20.51:22] ls -l /usr/bin/sealos 2&gt;/dev/null |wc -l
06:50:50 [INFO] [ssh.go:13] [ssh][172.24.20.52:22] ls -l /usr/bin/sealos 2&gt;/dev/null |wc -l
06:50:50 [DEBG] [ssh.go:25] [ssh][172.24.20.53:22]command result is: 0

06:50:50 [DEBG] [scp.go:27] [ssh]source file md5 value is b1fef37dd355c6d6842a20345a48b4fd
06:50:50 [DEBG] [ssh.go:25] [ssh][172.24.20.52:22]command result is: 0

06:50:50 [DEBG] [scp.go:27] [ssh]source file md5 value is b1fef37dd355c6d6842a20345a48b4fd
06:50:50 [DEBG] [ssh.go:25] [ssh][172.24.20.51:22]command result is: 1

06:50:50 [INFO] [ssh.go:13] [ssh][172.24.20.51:22] md5sum /usr/bin/sealos | cut -d&#34; &#34; -f1
06:50:51 [DEBG] [ssh.go:25] [ssh][172.24.20.51:22]command result is: b1fef37dd355c6d6842a20345a48b4fd

06:50:51 [INFO] [download.go:37] [172.24.20.51:22]SendPackage:  /usr/bin/sealos file is exist and ValidateMd5 success
06:50:51 [DEBG] [download.go:56] [172.24.20.51:22]please wait for after hook
06:50:51 [DEBG] [ssh.go:58] [172.24.20.51:22] chmod a+x /usr/bin/sealos
06:50:53 [INFO] [scp.go:101] [ssh][172.24.20.53:22]transfer total size is: 42.27MB ;speed is 42MB
06:50:53 [INFO] [ssh.go:13] [ssh][172.24.20.53:22] md5sum /usr/bin/sealos | cut -d&#34; &#34; -f1
06:50:53 [INFO] [scp.go:101] [ssh][172.24.20.52:22]transfer total size is: 42.27MB ;speed is 42MB
06:50:53 [INFO] [ssh.go:13] [ssh][172.24.20.52:22] md5sum /usr/bin/sealos | cut -d&#34; &#34; -f1
06:50:54 [DEBG] [ssh.go:25] [ssh][172.24.20.53:22]command result is: b1fef37dd355c6d6842a20345a48b4fd

06:50:54 [DEBG] [scp.go:30] [ssh]host: 172.24.20.53:22 , remote md5: b1fef37dd355c6d6842a20345a48b4fd
06:50:54 [INFO] [scp.go:34] [ssh]md5 validate true
06:50:54 [INFO] [download.go:50] [172.24.20.53:22]copy file md5 validate success
06:50:54 [DEBG] [download.go:56] [172.24.20.53:22]please wait for after hook
06:50:54 [DEBG] [ssh.go:58] [172.24.20.53:22] chmod a+x /usr/bin/sealos
06:50:54 [DEBG] [ssh.go:25] [ssh][172.24.20.52:22]command result is: b1fef37dd355c6d6842a20345a48b4fd

06:50:54 [DEBG] [scp.go:30] [ssh]host: 172.24.20.52:22 , remote md5: b1fef37dd355c6d6842a20345a48b4fd
06:50:54 [INFO] [scp.go:34] [ssh]md5 validate true
06:50:54 [INFO] [download.go:50] [172.24.20.52:22]copy file md5 validate success
06:50:54 [DEBG] [download.go:56] [172.24.20.52:22]please wait for after hook
06:50:54 [DEBG] [ssh.go:58] [172.24.20.52:22] chmod a+x /usr/bin/sealos
06:50:56 [DEBG] [ssh.go:58] [172.24.20.53:22] mkdir -p /root || true
06:50:56 [DEBG] [ssh.go:58] [172.24.20.51:22] mkdir -p /root || true
06:50:56 [DEBG] [ssh.go:58] [172.24.20.52:22] mkdir -p /root || true
06:50:57 [DEBG] [download.go:30] [172.24.20.53:22]please wait for mkDstDir
06:50:57 [INFO] [ssh.go:13] [ssh][172.24.20.53:22] ls -l /root/kube1.19.0.tar.gz 2&gt;/dev/null |wc -l
06:50:57 [DEBG] [download.go:30] [172.24.20.52:22]please wait for mkDstDir
06:50:57 [INFO] [ssh.go:13] [ssh][172.24.20.52:22] ls -l /root/kube1.19.0.tar.gz 2&gt;/dev/null |wc -l
06:50:57 [DEBG] [download.go:30] [172.24.20.51:22]please wait for mkDstDir
06:50:57 [INFO] [ssh.go:13] [ssh][172.24.20.51:22] ls -l /root/kube1.19.0.tar.gz 2&gt;/dev/null |wc -l
06:50:57 [DEBG] [ssh.go:25] [ssh][172.24.20.53:22]command result is: 0

06:50:57 [DEBG] [scp.go:27] [ssh]source file md5 value is bdd6c97922918f6070a65521df2a8b47
06:50:57 [DEBG] [ssh.go:25] [ssh][172.24.20.51:22]command result is: 1

06:50:57 [DEBG] [ssh.go:25] [ssh][172.24.20.52:22]command result is: 1

06:50:59 [INFO] [ssh.go:13] [ssh][172.24.20.51:22] md5sum /root/kube1.19.0.tar.gz | cut -d&#34; &#34; -f1
06:50:59 [INFO] [ssh.go:13] [ssh][172.24.20.52:22] md5sum /root/kube1.19.0.tar.gz | cut -d&#34; &#34; -f1
06:51:01 [DEBG] [ssh.go:25] [ssh][172.24.20.51:22]command result is: bdd6c97922918f6070a65521df2a8b47

06:51:01 [INFO] [download.go:37] [172.24.20.51:22]SendPackage:  /root/kube1.19.0.tar.gz file is exist and ValidateMd5 success
06:51:01 [DEBG] [download.go:56] [172.24.20.51:22]please wait for after hook
06:51:01 [DEBG] [ssh.go:58] [172.24.20.51:22] cd /root &amp;&amp; rm -rf kube &amp;&amp; tar zxvf kube1.19.0.tar.gz  &amp;&amp; cd /root/kube/shell &amp;&amp; rm -f ../bin/sealos &amp;&amp; bash init.sh &amp;&amp; sed -i &#39;/kubectl/d;/sealos/d&#39; /root/.bashrc  &amp;&amp; echo &#39;command -v kubectl &amp;&gt;/dev/null &amp;&amp; source &lt;(kubectl completion bash)&#39; &gt;&gt; /root/.bashrc &amp;&amp; echo &#39;[ -x /usr/bin/sealos ] &amp;&amp; source &lt;(sealos completion bash)&#39; &gt;&gt; /root/.bashrc &amp;&amp; source /root/.bashrc
06:51:02 [INFO] [ssh.go:51] [172.24.20.51:22] kube/
06:51:02 [INFO] [ssh.go:51] [172.24.20.51:22] kube/README.md
06:51:02 [INFO] [ssh.go:51] [172.24.20.51:22] kube/bin/
06:51:02 [INFO] [ssh.go:51] [172.24.20.51:22] kube/bin/kubeadm
06:51:03 [INFO] [scp.go:101] [ssh][172.24.20.53:22]transfer total size is: 100.00MB ;speed is 100MB
06:51:04 [DEBG] [ssh.go:25] [ssh][172.24.20.52:22]command result is: bdd6c97922918f6070a65521df2a8b47

06:51:04 [INFO] [download.go:37] [172.24.20.52:22]SendPackage:  /root/kube1.19.0.tar.gz file is exist and ValidateMd5 success
06:51:04 [DEBG] [download.go:56] [172.24.20.52:22]please wait for after hook
06:51:04 [DEBG] [ssh.go:58] [172.24.20.52:22] cd /root &amp;&amp; rm -rf kube &amp;&amp; tar zxvf kube1.19.0.tar.gz  &amp;&amp; cd /root/kube/shell &amp;&amp; rm -f ../bin/sealos &amp;&amp; bash init.sh &amp;&amp; sed -i &#39;/kubectl/d;/sealos/d&#39; /root/.bashrc  &amp;&amp; echo &#39;command -v kubectl &amp;&gt;/dev/null &amp;&amp; source &lt;(kubectl completion bash)&#39; &gt;&gt; /root/.bashrc &amp;&amp; echo &#39;[ -x /usr/bin/sealos ] &amp;&amp; source &lt;(sealos completion bash)&#39; &gt;&gt; /root/.bashrc &amp;&amp; source /root/.bashrc
06:51:04 [INFO] [ssh.go:51] [172.24.20.51:22] kube/bin/kubectl
06:51:04 [INFO] [ssh.go:51] [172.24.20.52:22] kube/
06:51:04 [INFO] [ssh.go:51] [172.24.20.52:22] kube/README.md
06:51:04 [INFO] [ssh.go:51] [172.24.20.52:22] kube/bin/
06:51:04 [INFO] [ssh.go:51] [172.24.20.52:22] kube/bin/kubeadm
06:51:05 [INFO] [ssh.go:51] [172.24.20.52:22] kube/bin/kubectl
06:51:06 [INFO] [ssh.go:51] [172.24.20.52:22] kube/bin/kubelet
06:51:06 [INFO] [ssh.go:51] [172.24.20.51:22] kube/bin/kubelet
06:51:08 [INFO] [ssh.go:51] [172.24.20.52:22] kube/bin/kubelet-pre-start.sh
06:51:08 [INFO] [ssh.go:51] [172.24.20.52:22] kube/bin/conntrack
06:51:08 [INFO] [ssh.go:51] [172.24.20.52:22] kube/bin/sealos
06:51:08 [INFO] [scp.go:101] [ssh][172.24.20.53:22]transfer total size is: 200.00MB ;speed is 100MB
06:51:09 [INFO] [ssh.go:51] [172.24.20.52:22] kube/conf/
06:51:09 [INFO] [ssh.go:51] [172.24.20.52:22] kube/conf/10-kubeadm.conf
06:51:09 [INFO] [ssh.go:51] [172.24.20.52:22] kube/conf/calico.yaml
06:51:09 [INFO] [ssh.go:51] [172.24.20.52:22] kube/conf/docker.service
06:51:09 [INFO] [ssh.go:51] [172.24.20.52:22] kube/conf/kubeadm.yaml
06:51:09 [INFO] [ssh.go:51] [172.24.20.52:22] kube/conf/kubelet.service
06:51:09 [INFO] [ssh.go:51] [172.24.20.52:22] kube/conf/net/
06:51:09 [INFO] [ssh.go:51] [172.24.20.52:22] kube/conf/net/calico.yaml
06:51:09 [INFO] [ssh.go:51] [172.24.20.52:22] kube/docker/
06:51:09 [INFO] [ssh.go:51] [172.24.20.52:22] kube/docker/docker.tgz
06:51:10 [INFO] [ssh.go:51] [172.24.20.52:22] kube/images/
06:51:10 [INFO] [ssh.go:51] [172.24.20.52:22] kube/images/images.tar
06:51:11 [INFO] [ssh.go:51] [172.24.20.51:22] kube/bin/kubelet-pre-start.sh
06:51:11 [INFO] [ssh.go:51] [172.24.20.51:22] kube/bin/conntrack
06:51:11 [INFO] [ssh.go:51] [172.24.20.51:22] kube/bin/sealos
06:51:14 [INFO] [ssh.go:51] [172.24.20.51:22] kube/conf/
06:51:14 [INFO] [ssh.go:51] [172.24.20.51:22] kube/conf/10-kubeadm.conf
06:51:14 [INFO] [ssh.go:51] [172.24.20.51:22] kube/conf/calico.yaml
06:51:14 [INFO] [ssh.go:51] [172.24.20.51:22] kube/conf/docker.service
06:51:14 [INFO] [ssh.go:51] [172.24.20.51:22] kube/conf/kubeadm.yaml
06:51:14 [INFO] [ssh.go:51] [172.24.20.51:22] kube/conf/kubelet.service
06:51:14 [INFO] [ssh.go:51] [172.24.20.51:22] kube/conf/net/
06:51:14 [INFO] [ssh.go:51] [172.24.20.51:22] kube/conf/net/calico.yaml
06:51:14 [INFO] [ssh.go:51] [172.24.20.51:22] kube/docker/
06:51:14 [INFO] [ssh.go:51] [172.24.20.51:22] kube/docker/docker.tgz
06:51:14 [INFO] [scp.go:101] [ssh][172.24.20.53:22]transfer total size is: 300.00MB ;speed is 100MB
06:51:16 [INFO] [ssh.go:51] [172.24.20.51:22] kube/images/
06:51:16 [INFO] [ssh.go:51] [172.24.20.51:22] kube/images/images.tar
06:51:19 [INFO] [scp.go:101] [ssh][172.24.20.53:22]transfer total size is: 400.00MB ;speed is 100MB
06:51:22 [INFO] [scp.go:101] [ssh][172.24.20.53:22]transfer total size is: 459.87MB ;speed is 59MB
06:51:22 [INFO] [ssh.go:13] [ssh][172.24.20.53:22] md5sum /root/kube1.19.0.tar.gz | cut -d&#34; &#34; -f1
06:51:24 [DEBG] [ssh.go:25] [ssh][172.24.20.53:22]command result is: bdd6c97922918f6070a65521df2a8b47

06:51:24 [DEBG] [scp.go:30] [ssh]host: 172.24.20.53:22 , remote md5: bdd6c97922918f6070a65521df2a8b47
06:51:24 [INFO] [scp.go:34] [ssh]md5 validate true
06:51:24 [INFO] [download.go:50] [172.24.20.53:22]copy file md5 validate success
06:51:24 [DEBG] [download.go:56] [172.24.20.53:22]please wait for after hook
06:51:24 [DEBG] [ssh.go:58] [172.24.20.53:22] cd /root &amp;&amp; rm -rf kube &amp;&amp; tar zxvf kube1.19.0.tar.gz  &amp;&amp; cd /root/kube/shell &amp;&amp; rm -f ../bin/sealos &amp;&amp; bash init.sh &amp;&amp; sed -i &#39;/kubectl/d;/sealos/d&#39; /root/.bashrc  &amp;&amp; echo &#39;command -v kubectl &amp;&gt;/dev/null &amp;&amp; source &lt;(kubectl completion bash)&#39; &gt;&gt; /root/.bashrc &amp;&amp; echo &#39;[ -x /usr/bin/sealos ] &amp;&amp; source &lt;(sealos completion bash)&#39; &gt;&gt; /root/.bashrc &amp;&amp; source /root/.bashrc
06:51:24 [INFO] [ssh.go:51] [172.24.20.53:22] kube/
06:51:24 [INFO] [ssh.go:51] [172.24.20.53:22] kube/README.md
06:51:24 [INFO] [ssh.go:51] [172.24.20.53:22] kube/bin/
06:51:24 [INFO] [ssh.go:51] [172.24.20.53:22] kube/bin/kubeadm
06:51:25 [INFO] [ssh.go:51] [172.24.20.53:22] kube/bin/kubectl
06:51:26 [INFO] [ssh.go:51] [172.24.20.53:22] kube/bin/kubelet
06:51:27 [INFO] [ssh.go:51] [172.24.20.53:22] kube/bin/kubelet-pre-start.sh
06:51:27 [INFO] [ssh.go:51] [172.24.20.53:22] kube/bin/conntrack
06:51:27 [INFO] [ssh.go:51] [172.24.20.53:22] kube/bin/sealos
06:51:28 [INFO] [ssh.go:51] [172.24.20.53:22] kube/conf/
06:51:28 [INFO] [ssh.go:51] [172.24.20.53:22] kube/conf/10-kubeadm.conf
06:51:28 [INFO] [ssh.go:51] [172.24.20.53:22] kube/conf/calico.yaml
06:51:28 [INFO] [ssh.go:51] [172.24.20.53:22] kube/conf/docker.service
06:51:28 [INFO] [ssh.go:51] [172.24.20.53:22] kube/conf/kubeadm.yaml
06:51:28 [INFO] [ssh.go:51] [172.24.20.53:22] kube/conf/kubelet.service
06:51:28 [INFO] [ssh.go:51] [172.24.20.53:22] kube/conf/net/
06:51:28 [INFO] [ssh.go:51] [172.24.20.53:22] kube/conf/net/calico.yaml
06:51:28 [INFO] [ssh.go:51] [172.24.20.53:22] kube/docker/
06:51:28 [INFO] [ssh.go:51] [172.24.20.53:22] kube/docker/docker.tgz
06:51:29 [INFO] [ssh.go:51] [172.24.20.53:22] kube/images/
06:51:29 [INFO] [ssh.go:51] [172.24.20.53:22] kube/images/images.tar
06:51:31 [INFO] [ssh.go:51] [172.24.20.52:22] kube/shell/
06:51:31 [INFO] [ssh.go:51] [172.24.20.52:22] kube/shell/init.sh
06:51:31 [INFO] [ssh.go:51] [172.24.20.52:22] kube/shell/master.sh
06:51:31 [INFO] [ssh.go:51] [172.24.20.52:22] kube/shell/docker.sh
06:51:31 [INFO] [ssh.go:51] [172.24.20.52:22] + storage=/var/lib/docker
06:51:31 [INFO] [ssh.go:51] [172.24.20.52:22] + harbor_ip=127.0.0.1
06:51:31 [INFO] [ssh.go:51] [172.24.20.52:22] + mkdir -p /var/lib/docker
06:51:31 [INFO] [ssh.go:51] [172.24.20.52:22] + command_exists docker
06:51:31 [INFO] [ssh.go:51] [172.24.20.52:22] + command -v docker
06:51:31 [INFO] [ssh.go:51] [172.24.20.52:22] + systemctl restart docker.service
06:51:33 [INFO] [ssh.go:51] [172.24.20.52:22] + docker version
06:51:33 [INFO] [ssh.go:51] [172.24.20.52:22] Client: Docker Engine - Community
06:51:33 [INFO] [ssh.go:51] [172.24.20.52:22]  Version:           19.03.0
06:51:33 [INFO] [ssh.go:51] [172.24.20.52:22]  API version:       1.40
06:51:33 [INFO] [ssh.go:51] [172.24.20.52:22]  Go version:        go1.12.5
06:51:33 [INFO] [ssh.go:51] [172.24.20.52:22]  Git commit:        aeac9490dc
06:51:33 [INFO] [ssh.go:51] [172.24.20.52:22]  Built:             Wed Jul 17 18:11:50 2019
06:51:33 [INFO] [ssh.go:51] [172.24.20.52:22]  OS/Arch:           linux/amd64
06:51:33 [INFO] [ssh.go:51] [172.24.20.52:22]  Experimental:      false
06:51:33 [INFO] [ssh.go:51] [172.24.20.52:22] 
06:51:33 [INFO] [ssh.go:51] [172.24.20.52:22] Server: Docker Engine - Community
06:51:33 [INFO] [ssh.go:51] [172.24.20.52:22]  Engine:
06:51:33 [INFO] [ssh.go:51] [172.24.20.52:22]   Version:          19.03.0
06:51:33 [INFO] [ssh.go:51] [172.24.20.52:22]   API version:      1.40 (minimum version 1.12)
06:51:33 [INFO] [ssh.go:51] [172.24.20.52:22]   Go version:       go1.12.5
06:51:33 [INFO] [ssh.go:51] [172.24.20.52:22]   Git commit:       aeac9490dc
06:51:33 [INFO] [ssh.go:51] [172.24.20.52:22]   Built:            Wed Jul 17 18:22:15 2019
06:51:33 [INFO] [ssh.go:51] [172.24.20.52:22]   OS/Arch:          linux/amd64
06:51:33 [INFO] [ssh.go:51] [172.24.20.52:22]   Experimental:     false
06:51:33 [INFO] [ssh.go:51] [172.24.20.52:22]  containerd:
06:51:33 [INFO] [ssh.go:51] [172.24.20.52:22]   Version:          v1.2.6
06:51:33 [INFO] [ssh.go:51] [172.24.20.52:22]   GitCommit:        894b81a4b802e4eb2a91d1ce216b8817763c29fb
06:51:33 [INFO] [ssh.go:51] [172.24.20.52:22]  runc:
06:51:33 [INFO] [ssh.go:51] [172.24.20.52:22]   Version:          1.0.0-rc8
06:51:33 [INFO] [ssh.go:51] [172.24.20.52:22]   GitCommit:        425e105d5a03fabd737a126ad93d62a9eeede87f
06:51:33 [INFO] [ssh.go:51] [172.24.20.52:22]  docker-init:
06:51:33 [INFO] [ssh.go:51] [172.24.20.52:22]   Version:          0.18.0
06:51:33 [INFO] [ssh.go:51] [172.24.20.52:22]   GitCommit:        fec3683
06:51:34 [INFO] [ssh.go:51] [172.24.20.52:22] modprobe: FATAL: Module nf_conntrack_ipv4 not found in directory /lib/modules/5.4.119-20.0009.20
06:51:34 [INFO] [ssh.go:51] [172.24.20.52:22] * Applying /usr/lib/sysctl.d/00-tencentos.conf ...
06:51:34 [INFO] [ssh.go:51] [172.24.20.52:22] kernel.printk = 4
06:51:34 [INFO] [ssh.go:51] [172.24.20.52:22] net.ipv6.conf.all.disable_ipv6 = 0
06:51:34 [INFO] [ssh.go:51] [172.24.20.52:22] vm.oom_dump_tasks = 1
06:51:34 [INFO] [ssh.go:51] [172.24.20.52:22] kernel.ctrl-alt-del = 0
06:51:34 [INFO] [ssh.go:51] [172.24.20.52:22] kernel.sysrq_use_leftctrl = 1
06:51:34 [INFO] [ssh.go:51] [172.24.20.52:22] net.ipv4.ip_local_reserved_ports = 48369,36000,56000
06:51:34 [INFO] [ssh.go:51] [172.24.20.52:22] * Applying /usr/lib/sysctl.d/10-default-yama-scope.conf ...
06:51:34 [INFO] [ssh.go:51] [172.24.20.52:22] kernel.yama.ptrace_scope = 0
06:51:34 [INFO] [ssh.go:51] [172.24.20.52:22] * Applying /usr/lib/sysctl.d/50-coredump.conf ...
06:51:34 [INFO] [ssh.go:51] [172.24.20.52:22] kernel.core_pattern = |/usr/lib/systemd/systemd-coredump %P %u %g %s %t %c %h %e
06:51:34 [INFO] [ssh.go:51] [172.24.20.52:22] kernel.core_pipe_limit = 16
06:51:34 [INFO] [ssh.go:51] [172.24.20.52:22] * Applying /usr/lib/sysctl.d/50-default.conf ...
06:51:34 [INFO] [ssh.go:51] [172.24.20.52:22] kernel.sysrq = 16
06:51:34 [INFO] [ssh.go:51] [172.24.20.52:22] kernel.core_uses_pid = 1
06:51:34 [INFO] [ssh.go:51] [172.24.20.52:22] kernel.kptr_restrict = 1
06:51:34 [INFO] [ssh.go:51] [172.24.20.52:22] net.ipv4.conf.all.rp_filter = 1
06:51:34 [INFO] [ssh.go:51] [172.24.20.52:22] net.ipv4.conf.all.accept_source_route = 0
06:51:34 [INFO] [ssh.go:51] [172.24.20.52:22] net.ipv4.conf.all.promote_secondaries = 1
06:51:34 [INFO] [ssh.go:51] [172.24.20.52:22] net.core.default_qdisc = fq_codel
06:51:34 [INFO] [ssh.go:51] [172.24.20.52:22] fs.protected_hardlinks = 1
06:51:34 [INFO] [ssh.go:51] [172.24.20.52:22] fs.protected_symlinks = 1
06:51:34 [INFO] [ssh.go:51] [172.24.20.52:22] * Applying /usr/lib/sysctl.d/50-libkcapi-optmem_max.conf ...
06:51:34 [INFO] [ssh.go:51] [172.24.20.52:22] net.core.optmem_max = 81920
06:51:34 [INFO] [ssh.go:51] [172.24.20.52:22] * Applying /usr/lib/sysctl.d/50-pid-max.conf ...
06:51:34 [INFO] [ssh.go:51] [172.24.20.52:22] kernel.pid_max = 4194304
06:51:34 [INFO] [ssh.go:51] [172.24.20.52:22] * Applying /etc/sysctl.d/99-sysctl.conf ...
06:51:34 [INFO] [ssh.go:51] [172.24.20.52:22] * Applying /etc/sysctl.d/k8s.conf ...
06:51:34 [INFO] [ssh.go:51] [172.24.20.52:22] net.bridge.bridge-nf-call-ip6tables = 1
06:51:34 [INFO] [ssh.go:51] [172.24.20.52:22] net.bridge.bridge-nf-call-iptables = 1
06:51:34 [INFO] [ssh.go:51] [172.24.20.52:22] * Applying /etc/sysctl.conf ...
06:51:34 [INFO] [ssh.go:51] [172.24.20.52:22] net.ipv4.ip_forward = 1
06:51:34 [INFO] [ssh.go:51] [172.24.20.52:22] setenforce: SELinux is disabled
06:51:40 [INFO] [ssh.go:51] [172.24.20.51:22] kube/shell/
06:51:40 [INFO] [ssh.go:51] [172.24.20.51:22] kube/shell/init.sh
06:51:40 [INFO] [ssh.go:51] [172.24.20.51:22] kube/shell/master.sh
06:51:40 [INFO] [ssh.go:51] [172.24.20.51:22] kube/shell/docker.sh
06:51:40 [INFO] [ssh.go:51] [172.24.20.51:22] + storage=/var/lib/docker
06:51:40 [INFO] [ssh.go:51] [172.24.20.51:22] + harbor_ip=127.0.0.1
06:51:40 [INFO] [ssh.go:51] [172.24.20.51:22] + mkdir -p /var/lib/docker
06:51:40 [INFO] [ssh.go:51] [172.24.20.51:22] + command_exists docker
06:51:40 [INFO] [ssh.go:51] [172.24.20.51:22] + command -v docker
06:51:40 [INFO] [ssh.go:51] [172.24.20.51:22] + systemctl restart docker.service
06:51:43 [INFO] [ssh.go:51] [172.24.20.51:22] + docker version
06:51:43 [INFO] [ssh.go:51] [172.24.20.51:22] Client: Docker Engine - Community
06:51:43 [INFO] [ssh.go:51] [172.24.20.51:22]  Version:           19.03.0
06:51:43 [INFO] [ssh.go:51] [172.24.20.51:22]  API version:       1.40
06:51:43 [INFO] [ssh.go:51] [172.24.20.51:22]  Go version:        go1.12.5
06:51:43 [INFO] [ssh.go:51] [172.24.20.51:22]  Git commit:        aeac9490dc
06:51:43 [INFO] [ssh.go:51] [172.24.20.51:22]  Built:             Wed Jul 17 18:11:50 2019
06:51:43 [INFO] [ssh.go:51] [172.24.20.51:22]  OS/Arch:           linux/amd64
06:51:43 [INFO] [ssh.go:51] [172.24.20.51:22]  Experimental:      false
06:51:43 [INFO] [ssh.go:51] [172.24.20.51:22] 
06:51:43 [INFO] [ssh.go:51] [172.24.20.51:22] Server: Docker Engine - Community
06:51:43 [INFO] [ssh.go:51] [172.24.20.51:22]  Engine:
06:51:43 [INFO] [ssh.go:51] [172.24.20.51:22]   Version:          19.03.0
06:51:43 [INFO] [ssh.go:51] [172.24.20.51:22]   API version:      1.40 (minimum version 1.12)
06:51:43 [INFO] [ssh.go:51] [172.24.20.51:22]   Go version:       go1.12.5
06:51:43 [INFO] [ssh.go:51] [172.24.20.51:22]   Git commit:       aeac9490dc
06:51:43 [INFO] [ssh.go:51] [172.24.20.51:22]   Built:            Wed Jul 17 18:22:15 2019
06:51:43 [INFO] [ssh.go:51] [172.24.20.51:22]   OS/Arch:          linux/amd64
06:51:43 [INFO] [ssh.go:51] [172.24.20.51:22]   Experimental:     false
06:51:43 [INFO] [ssh.go:51] [172.24.20.51:22]  containerd:
06:51:43 [INFO] [ssh.go:51] [172.24.20.51:22]   Version:          v1.2.6
06:51:43 [INFO] [ssh.go:51] [172.24.20.51:22]   GitCommit:        894b81a4b802e4eb2a91d1ce216b8817763c29fb
06:51:43 [INFO] [ssh.go:51] [172.24.20.51:22]  runc:
06:51:43 [INFO] [ssh.go:51] [172.24.20.51:22]   Version:          1.0.0-rc8
06:51:43 [INFO] [ssh.go:51] [172.24.20.51:22]   GitCommit:        425e105d5a03fabd737a126ad93d62a9eeede87f
06:51:43 [INFO] [ssh.go:51] [172.24.20.51:22]  docker-init:
06:51:43 [INFO] [ssh.go:51] [172.24.20.51:22]   Version:          0.18.0
06:51:43 [INFO] [ssh.go:51] [172.24.20.51:22]   GitCommit:        fec3683
06:51:43 [INFO] [ssh.go:51] [172.24.20.51:22] modprobe: FATAL: Module nf_conntrack_ipv4 not found in directory /lib/modules/5.4.119-20.0009.20
06:51:43 [INFO] [ssh.go:51] [172.24.20.51:22] * Applying /usr/lib/sysctl.d/00-tencentos.conf ...
06:51:43 [INFO] [ssh.go:51] [172.24.20.51:22] kernel.printk = 4
06:51:43 [INFO] [ssh.go:51] [172.24.20.51:22] net.ipv6.conf.all.disable_ipv6 = 0
06:51:43 [INFO] [ssh.go:51] [172.24.20.51:22] vm.oom_dump_tasks = 1
06:51:43 [INFO] [ssh.go:51] [172.24.20.51:22] kernel.ctrl-alt-del = 0
06:51:43 [INFO] [ssh.go:51] [172.24.20.51:22] kernel.sysrq_use_leftctrl = 1
06:51:43 [INFO] [ssh.go:51] [172.24.20.51:22] net.ipv4.ip_local_reserved_ports = 48369,36000,56000
06:51:43 [INFO] [ssh.go:51] [172.24.20.51:22] * Applying /usr/lib/sysctl.d/10-default-yama-scope.conf ...
06:51:43 [INFO] [ssh.go:51] [172.24.20.51:22] kernel.yama.ptrace_scope = 0
06:51:43 [INFO] [ssh.go:51] [172.24.20.51:22] * Applying /usr/lib/sysctl.d/50-coredump.conf ...
06:51:43 [INFO] [ssh.go:51] [172.24.20.51:22] kernel.core_pattern = |/usr/lib/systemd/systemd-coredump %P %u %g %s %t %c %h %e
06:51:43 [INFO] [ssh.go:51] [172.24.20.51:22] kernel.core_pipe_limit = 16
06:51:43 [INFO] [ssh.go:51] [172.24.20.51:22] * Applying /usr/lib/sysctl.d/50-default.conf ...
06:51:43 [INFO] [ssh.go:51] [172.24.20.51:22] kernel.sysrq = 16
06:51:43 [INFO] [ssh.go:51] [172.24.20.51:22] kernel.core_uses_pid = 1
06:51:43 [INFO] [ssh.go:51] [172.24.20.51:22] kernel.kptr_restrict = 1
06:51:43 [INFO] [ssh.go:51] [172.24.20.51:22] net.ipv4.conf.all.rp_filter = 1
06:51:43 [INFO] [ssh.go:51] [172.24.20.51:22] net.ipv4.conf.all.accept_source_route = 0
06:51:43 [INFO] [ssh.go:51] [172.24.20.51:22] net.ipv4.conf.all.promote_secondaries = 1
06:51:43 [INFO] [ssh.go:51] [172.24.20.51:22] net.core.default_qdisc = fq_codel
06:51:43 [INFO] [ssh.go:51] [172.24.20.51:22] fs.protected_hardlinks = 1
06:51:43 [INFO] [ssh.go:51] [172.24.20.51:22] fs.protected_symlinks = 1
06:51:43 [INFO] [ssh.go:51] [172.24.20.51:22] * Applying /usr/lib/sysctl.d/50-libkcapi-optmem_max.conf ...
06:51:43 [INFO] [ssh.go:51] [172.24.20.51:22] net.core.optmem_max = 81920
06:51:43 [INFO] [ssh.go:51] [172.24.20.51:22] * Applying /usr/lib/sysctl.d/50-pid-max.conf ...
06:51:43 [INFO] [ssh.go:51] [172.24.20.51:22] kernel.pid_max = 4194304
06:51:43 [INFO] [ssh.go:51] [172.24.20.51:22] * Applying /etc/sysctl.d/99-sysctl.conf ...
06:51:43 [INFO] [ssh.go:51] [172.24.20.51:22] * Applying /etc/sysctl.d/k8s.conf ...
06:51:43 [INFO] [ssh.go:51] [172.24.20.51:22] net.bridge.bridge-nf-call-ip6tables = 1
06:51:43 [INFO] [ssh.go:51] [172.24.20.51:22] net.bridge.bridge-nf-call-iptables = 1
06:51:43 [INFO] [ssh.go:51] [172.24.20.51:22] * Applying /etc/sysctl.conf ...
06:51:43 [INFO] [ssh.go:51] [172.24.20.51:22] net.ipv4.ip_forward = 1
06:51:45 [INFO] [ssh.go:51] [172.24.20.51:22] setenforce: SELinux is disabled
06:51:51 [INFO] [ssh.go:51] [172.24.20.52:22] Loaded image: k8s.gcr.io/kube-controller-manager:v1.19.0
06:51:51 [INFO] [ssh.go:51] [172.24.20.52:22] Loaded image: k8s.gcr.io/kube-apiserver:v1.19.0
06:51:51 [INFO] [ssh.go:51] [172.24.20.52:22] Loaded image: k8s.gcr.io/etcd:3.4.9-1
06:51:51 [INFO] [ssh.go:51] [172.24.20.52:22] Loaded image: k8s.gcr.io/pause:3.2
06:51:51 [INFO] [ssh.go:51] [172.24.20.52:22] Loaded image: calico/kube-controllers:v3.8.2
06:51:51 [INFO] [ssh.go:51] [172.24.20.52:22] Loaded image: k8s.gcr.io/kube-proxy:v1.19.0
06:51:51 [INFO] [ssh.go:51] [172.24.20.52:22] Loaded image: k8s.gcr.io/kube-scheduler:v1.19.0
06:51:51 [INFO] [ssh.go:51] [172.24.20.52:22] Loaded image: k8s.gcr.io/coredns:1.7.0
06:51:51 [INFO] [ssh.go:51] [172.24.20.52:22] Loaded image: calico/node:v3.8.2
06:51:51 [INFO] [ssh.go:51] [172.24.20.52:22] Loaded image: calico/cni:v3.8.2
06:51:51 [INFO] [ssh.go:51] [172.24.20.52:22] Loaded image: calico/pod2daemon-flexvol:v3.8.2
06:51:55 [INFO] [ssh.go:51] [172.24.20.52:22] driver is cgroupfs
06:51:55 [INFO] [ssh.go:51] [172.24.20.53:22] kube/shell/
06:51:55 [INFO] [ssh.go:51] [172.24.20.53:22] kube/shell/init.sh
06:51:55 [INFO] [ssh.go:51] [172.24.20.53:22] kube/shell/master.sh
06:51:55 [INFO] [ssh.go:51] [172.24.20.53:22] kube/shell/docker.sh
06:51:55 [INFO] [ssh.go:51] [172.24.20.53:22] + storage=/var/lib/docker
06:51:55 [INFO] [ssh.go:51] [172.24.20.53:22] + harbor_ip=127.0.0.1
06:51:55 [INFO] [ssh.go:51] [172.24.20.53:22] + mkdir -p /var/lib/docker
06:51:55 [INFO] [ssh.go:51] [172.24.20.53:22] + command_exists docker
06:51:55 [INFO] [ssh.go:51] [172.24.20.53:22] + command -v docker
06:51:55 [INFO] [ssh.go:51] [172.24.20.53:22] ++ get_distribution
06:51:55 [INFO] [ssh.go:51] [172.24.20.53:22] ++ lsb_dist=
06:51:55 [INFO] [ssh.go:51] [172.24.20.53:22] ++ &#39;[&#39; -r /etc/os-release &#39;]&#39;
06:51:55 [INFO] [ssh.go:51] [172.24.20.53:22] +++ . /etc/os-release
06:51:55 [INFO] [ssh.go:51] [172.24.20.53:22] ++++ NAME=OpenCloudOS
06:51:55 [INFO] [ssh.go:51] [172.24.20.53:22] ++++ VERSION=8.6
06:51:55 [INFO] [ssh.go:51] [172.24.20.53:22] ++++ ID=opencloudos
06:51:55 [INFO] [ssh.go:51] [172.24.20.53:22] ++++ ID_LIKE=&#39;rhel fedora&#39;
06:51:55 [INFO] [ssh.go:51] [172.24.20.53:22] ++++ VERSION_ID=8.6
06:51:55 [INFO] [ssh.go:51] [172.24.20.53:22] ++++ PLATFORM_ID=platform:oc8
06:51:55 [INFO] [ssh.go:51] [172.24.20.53:22] ++++ PRETTY_NAME=&#39;OpenCloudOS 8.6&#39;
06:51:55 [INFO] [ssh.go:51] [172.24.20.53:22] ++++ ANSI_COLOR=&#39;0;31&#39;
06:51:55 [INFO] [ssh.go:51] [172.24.20.53:22] ++++ CPE_NAME=cpe:/o:opencloudos:opencloudos:8
06:51:55 [INFO] [ssh.go:51] [172.24.20.53:22] ++++ HOME_URL=https://www.opencloudos.org/
06:51:55 [INFO] [ssh.go:51] [172.24.20.53:22] ++++ BUG_REPORT_URL=https://bugs.opencloudos.tech/
06:51:55 [INFO] [ssh.go:51] [172.24.20.53:22] +++ echo opencloudos
06:51:55 [INFO] [ssh.go:51] [172.24.20.53:22] ++ lsb_dist=opencloudos
06:51:55 [INFO] [ssh.go:51] [172.24.20.53:22] ++ echo opencloudos
06:51:55 [INFO] [ssh.go:51] [172.24.20.53:22] + lsb_dist=opencloudos
06:51:55 [INFO] [ssh.go:51] [172.24.20.53:22] ++ echo opencloudos
06:51:55 [INFO] [ssh.go:51] [172.24.20.53:22] ++ tr &#39;[:upper:]&#39; &#39;[:lower:]&#39;
06:51:55 [INFO] [ssh.go:51] [172.24.20.53:22] + lsb_dist=opencloudos
06:51:55 [INFO] [ssh.go:51] [172.24.20.53:22] + echo &#39;current system is opencloudos&#39;
06:51:55 [INFO] [ssh.go:51] [172.24.20.53:22] current system is opencloudos
06:51:55 [INFO] [ssh.go:51] [172.24.20.53:22] + case &#34;$lsb_dist&#34; in
06:51:55 [INFO] [ssh.go:51] [172.24.20.53:22] + cp ../conf/docker.service /usr/lib/systemd/system/docker.service
06:51:55 [INFO] [ssh.go:51] [172.24.20.53:22] + tar --strip-components=1 -xvzf ../docker/docker.tgz -C /usr/bin
06:51:56 [INFO] [ssh.go:51] [172.24.20.53:22] docker/ctr
06:51:57 [INFO] [ssh.go:51] [172.24.20.53:22] docker/runc
06:51:57 [INFO] [ssh.go:51] [172.24.20.53:22] docker/dockerd
06:51:59 [INFO] [ssh.go:51] [172.24.20.53:22] docker/docker
06:52:01 [INFO] [ssh.go:51] [172.24.20.53:22] docker/containerd
06:52:02 [INFO] [ssh.go:51] [172.24.20.53:22] docker/docker-init
06:52:02 [INFO] [ssh.go:51] [172.24.20.53:22] docker/containerd-shim
06:52:03 [INFO] [ssh.go:51] [172.24.20.53:22] docker/docker-proxy
06:52:03 [INFO] [ssh.go:51] [172.24.20.53:22] + chmod a+x /usr/bin
06:52:03 [INFO] [ssh.go:51] [172.24.20.53:22] + systemctl enable docker.service
06:52:03 [INFO] [ssh.go:51] [172.24.20.53:22] Created symlink /etc/systemd/system/multi-user.target.wants/docker.service → /usr/lib/systemd/system/docker.service.
06:52:04 [INFO] [ssh.go:51] [172.24.20.53:22] + systemctl restart docker.service
06:52:06 [INFO] [ssh.go:51] [172.24.20.53:22] + cat
06:52:06 [INFO] [ssh.go:51] [172.24.20.53:22] + systemctl restart docker.service
06:52:06 [INFO] [ssh.go:51] [172.24.20.51:22] Loaded image: k8s.gcr.io/kube-controller-manager:v1.19.0
06:52:06 [INFO] [ssh.go:51] [172.24.20.51:22] Loaded image: k8s.gcr.io/kube-apiserver:v1.19.0
06:52:06 [INFO] [ssh.go:51] [172.24.20.51:22] Loaded image: k8s.gcr.io/etcd:3.4.9-1
06:52:06 [INFO] [ssh.go:51] [172.24.20.51:22] Loaded image: k8s.gcr.io/pause:3.2
06:52:06 [INFO] [ssh.go:51] [172.24.20.51:22] Loaded image: calico/kube-controllers:v3.8.2
06:52:06 [INFO] [ssh.go:51] [172.24.20.51:22] Loaded image: k8s.gcr.io/kube-proxy:v1.19.0
06:52:06 [INFO] [ssh.go:51] [172.24.20.51:22] Loaded image: k8s.gcr.io/kube-scheduler:v1.19.0
06:52:06 [INFO] [ssh.go:51] [172.24.20.51:22] Loaded image: k8s.gcr.io/coredns:1.7.0
06:52:06 [INFO] [ssh.go:51] [172.24.20.51:22] Loaded image: calico/node:v3.8.2
06:52:06 [INFO] [ssh.go:51] [172.24.20.51:22] Loaded image: calico/cni:v3.8.2
06:52:06 [INFO] [ssh.go:51] [172.24.20.51:22] Loaded image: calico/pod2daemon-flexvol:v3.8.2
06:52:09 [INFO] [ssh.go:51] [172.24.20.53:22] + docker version
06:52:09 [INFO] [ssh.go:51] [172.24.20.53:22] Client: Docker Engine - Community
06:52:09 [INFO] [ssh.go:51] [172.24.20.53:22]  Version:           19.03.0
06:52:09 [INFO] [ssh.go:51] [172.24.20.53:22]  API version:       1.40
06:52:09 [INFO] [ssh.go:51] [172.24.20.53:22]  Go version:        go1.12.5
06:52:09 [INFO] [ssh.go:51] [172.24.20.53:22]  Git commit:        aeac9490dc
06:52:09 [INFO] [ssh.go:51] [172.24.20.53:22]  Built:             Wed Jul 17 18:11:50 2019
06:52:09 [INFO] [ssh.go:51] [172.24.20.53:22]  OS/Arch:           linux/amd64
06:52:09 [INFO] [ssh.go:51] [172.24.20.53:22]  Experimental:      false
06:52:09 [INFO] [ssh.go:51] [172.24.20.53:22] 
06:52:09 [INFO] [ssh.go:51] [172.24.20.53:22] Server: Docker Engine - Community
06:52:09 [INFO] [ssh.go:51] [172.24.20.53:22]  Engine:
06:52:09 [INFO] [ssh.go:51] [172.24.20.53:22]   Version:          19.03.0
06:52:09 [INFO] [ssh.go:51] [172.24.20.53:22]   API version:      1.40 (minimum version 1.12)
06:52:09 [INFO] [ssh.go:51] [172.24.20.53:22]   Go version:       go1.12.5
06:52:09 [INFO] [ssh.go:51] [172.24.20.53:22]   Git commit:       aeac9490dc
06:52:09 [INFO] [ssh.go:51] [172.24.20.53:22]   Built:            Wed Jul 17 18:22:15 2019
06:52:09 [INFO] [ssh.go:51] [172.24.20.53:22]   OS/Arch:          linux/amd64
06:52:09 [INFO] [ssh.go:51] [172.24.20.53:22]   Experimental:     false
06:52:09 [INFO] [ssh.go:51] [172.24.20.53:22]  containerd:
06:52:09 [INFO] [ssh.go:51] [172.24.20.53:22]   Version:          v1.2.6
06:52:09 [INFO] [ssh.go:51] [172.24.20.53:22]   GitCommit:        894b81a4b802e4eb2a91d1ce216b8817763c29fb
06:52:09 [INFO] [ssh.go:51] [172.24.20.53:22]  runc:
06:52:09 [INFO] [ssh.go:51] [172.24.20.53:22]   Version:          1.0.0-rc8
06:52:09 [INFO] [ssh.go:51] [172.24.20.53:22]   GitCommit:        425e105d5a03fabd737a126ad93d62a9eeede87f
06:52:09 [INFO] [ssh.go:51] [172.24.20.53:22]  docker-init:
06:52:09 [INFO] [ssh.go:51] [172.24.20.53:22]   Version:          0.18.0
06:52:09 [INFO] [ssh.go:51] [172.24.20.53:22]   GitCommit:        fec3683
06:52:09 [INFO] [ssh.go:51] [172.24.20.53:22] modprobe: FATAL: Module nf_conntrack_ipv4 not found in directory /lib/modules/5.4.119-20.0009.20
06:52:09 [INFO] [ssh.go:51] [172.24.20.53:22] * Applying /usr/lib/sysctl.d/00-tencentos.conf ...
06:52:09 [INFO] [ssh.go:51] [172.24.20.53:22] kernel.printk = 4
06:52:09 [INFO] [ssh.go:51] [172.24.20.53:22] net.ipv6.conf.all.disable_ipv6 = 0
06:52:09 [INFO] [ssh.go:51] [172.24.20.53:22] vm.oom_dump_tasks = 1
06:52:09 [INFO] [ssh.go:51] [172.24.20.53:22] kernel.ctrl-alt-del = 0
06:52:09 [INFO] [ssh.go:51] [172.24.20.53:22] kernel.sysrq_use_leftctrl = 1
06:52:09 [INFO] [ssh.go:51] [172.24.20.53:22] net.ipv4.ip_local_reserved_ports = 48369,36000,56000
06:52:09 [INFO] [ssh.go:51] [172.24.20.53:22] * Applying /usr/lib/sysctl.d/10-default-yama-scope.conf ...
06:52:09 [INFO] [ssh.go:51] [172.24.20.53:22] kernel.yama.ptrace_scope = 0
06:52:09 [INFO] [ssh.go:51] [172.24.20.53:22] * Applying /usr/lib/sysctl.d/50-coredump.conf ...
06:52:09 [INFO] [ssh.go:51] [172.24.20.53:22] kernel.core_pattern = |/usr/lib/systemd/systemd-coredump %P %u %g %s %t %c %h %e
06:52:09 [INFO] [ssh.go:51] [172.24.20.53:22] kernel.core_pipe_limit = 16
06:52:09 [INFO] [ssh.go:51] [172.24.20.53:22] * Applying /usr/lib/sysctl.d/50-default.conf ...
06:52:09 [INFO] [ssh.go:51] [172.24.20.53:22] kernel.sysrq = 16
06:52:09 [INFO] [ssh.go:51] [172.24.20.53:22] kernel.core_uses_pid = 1
06:52:09 [INFO] [ssh.go:51] [172.24.20.53:22] kernel.kptr_restrict = 1
06:52:09 [INFO] [ssh.go:51] [172.24.20.53:22] net.ipv4.conf.all.rp_filter = 1
06:52:09 [INFO] [ssh.go:51] [172.24.20.53:22] net.ipv4.conf.all.accept_source_route = 0
06:52:09 [INFO] [ssh.go:51] [172.24.20.53:22] net.ipv4.conf.all.promote_secondaries = 1
06:52:09 [INFO] [ssh.go:51] [172.24.20.53:22] net.core.default_qdisc = fq_codel
06:52:09 [INFO] [ssh.go:51] [172.24.20.53:22] fs.protected_hardlinks = 1
06:52:09 [INFO] [ssh.go:51] [172.24.20.53:22] fs.protected_symlinks = 1
06:52:09 [INFO] [ssh.go:51] [172.24.20.53:22] * Applying /usr/lib/sysctl.d/50-libkcapi-optmem_max.conf ...
06:52:09 [INFO] [ssh.go:51] [172.24.20.53:22] net.core.optmem_max = 81920
06:52:09 [INFO] [ssh.go:51] [172.24.20.53:22] * Applying /usr/lib/sysctl.d/50-pid-max.conf ...
06:52:09 [INFO] [ssh.go:51] [172.24.20.53:22] kernel.pid_max = 4194304
06:52:09 [INFO] [ssh.go:51] [172.24.20.53:22] * Applying /etc/sysctl.d/99-sysctl.conf ...
06:52:09 [INFO] [ssh.go:51] [172.24.20.53:22] * Applying /etc/sysctl.d/k8s.conf ...
06:52:09 [INFO] [ssh.go:51] [172.24.20.53:22] net.bridge.bridge-nf-call-ip6tables = 1
06:52:09 [INFO] [ssh.go:51] [172.24.20.53:22] net.bridge.bridge-nf-call-iptables = 1
06:52:09 [INFO] [ssh.go:51] [172.24.20.53:22] * Applying /etc/sysctl.conf ...
06:52:09 [INFO] [ssh.go:51] [172.24.20.53:22] net.ipv4.ip_forward = 1
06:52:09 [INFO] [ssh.go:51] [172.24.20.51:22] driver is cgroupfs
06:52:10 [INFO] [ssh.go:51] [172.24.20.53:22] setenforce: SELinux is disabled
79d541cda6cb: Loading layer  3.041MB/3.041MB
e9933a1f21f5: Loading layer  1.734MB/1.734MB
d85a13cfa53e: Loading layer  107.3MB/107.3MB
Loaded image: k8s.gcr.io/kube-controller-manager:v1.19.0
c3a6120d2fd6: Loading layer  115.2MB/115.2MB
Loaded image: k8s.gcr.io/kube-apiserver:v1.19.0
0d1435bd79e4: Loading layer  3.062MB/3.062MB
2aef7a73d4b0: Loading layer   2.13MB/2.13MB
ec3830e15d9c: Loading layer  225.3MB/225.3MB
4d5d7883c216: Loading layer   2.19MB/2.19MB
5d3a32005e6b: Loading layer  21.95MB/21.95MB
Loaded image: k8s.gcr.io/etcd:3.4.9-10.53:22] 
ba0dae6243cc: Loading layer  684.5kB/684.5kB
Loaded image: k8s.gcr.io/pause:3.24.20.53:22] 
8b62fd4eb2dd: Loading layer  43.99MB/43.99MB
40fe7b163104: Loading layer  2.828MB/2.828MB
Loaded image: calico/kube-controllers:v3.8.2] 
91e3a07063b3: Loading layer  53.89MB/53.89MB
b4e54f331697: Loading layer  21.78MB/21.78MB
b9b82a97c787: Loading layer  5.168MB/5.168MB
1b55846906e8: Loading layer  4.608kB/4.608kB
061bfb5cb861: Loading layer  8.192kB/8.192kB
78dd6c0504a7: Loading layer  8.704kB/8.704kB
f83925edb29c: Loading layer  38.81MB/38.81MB
Loaded image: k8s.gcr.io/kube-proxy:v1.19.02] 
a2a6ea4dde58: Loading layer  42.13MB/42.13MB
Loaded image: k8s.gcr.io/kube-scheduler:v1.19.0
225df95e717c: Loading layer  336.4kB/336.4kB
96d17b0b58a7: Loading layer  45.02MB/45.02MB
Loaded image: k8s.gcr.io/coredns:1.7.0.53:22] 
d8a33133e477: Loading layer  72.47MB/72.47MB
337ec577cf9c: Loading layer     33MB/33MB
45cc6dfacce1: Loading layer  3.584kB/3.584kB
7b3ecdc818b0: Loading layer  3.584kB/3.584kB
2b0805a50f82: Loading layer  21.85MB/21.85MB
c9bf76343513: Loading layer  11.26kB/11.26kB
f4176618c27b: Loading layer  11.26kB/11.26kB
4dcaff1da822: Loading layer   6.55MB/6.55MB
92e6b8f58573: Loading layer  2.945MB/2.945MB
5f970d4ac62d: Loading layer  35.84kB/35.84kB
b1a2a2446599: Loading layer  55.22MB/55.22MB
014866f8df9e: Loading layer   1.14MB/1.14MB
Loaded image: calico/node:v3.8.2.24.20.53:22] 
466b4a33898e: Loading layer  88.05MB/88.05MB
dd824a99572a: Loading layer  10.24kB/10.24kB
d8fdd74cc7ed: Loading layer   2.56kB/2.56kB
Loaded image: calico/cni:v3.8.22.24.20.53:22] 
3fc64803ca2d: Loading layer  4.463MB/4.463MB
f03a403b18a7: Loading layer   5.12kB/5.12kB
0de6f9b8b1f7: Loading layer  5.166MB/5.166MB
Loaded image: calico/pod2daemon-flexvol:v3.8.2
06:52:52 [INFO] [ssh.go:51] [172.24.20.53:22] driver is cgroupfs
06:52:52 [INFO] [ssh.go:51] [172.24.20.53:22] Created symlink /etc/systemd/system/multi-user.target.wants/kubelet.service → /etc/systemd/system/kubelet.service.
06:52:53 [DEBG] [print.go:21] ==&gt;SendPackage
06:52:53 [DEBG] [ssh.go:58] [172.24.20.51:22] echo &#34;apiVersion: kubeadm.k8s.io/v1beta1
kind: InitConfiguration
localAPIEndpoint:
  advertiseAddress: 172.24.20.51
  bindPort: 6443
---
apiVersion: kubeadm.k8s.io/v1beta1
kind: ClusterConfiguration
kubernetesVersion: v1.19.0
controlPlaneEndpoint: &#34;apiserver.cluster.local:6443&#34;
imageRepository: k8s.gcr.io
networking:
  # dnsDomain: cluster.local
  podSubnet: 10.20.0.0/16
  serviceSubnet: 10.40.0.0/16
apiServer:
  certSANs:
  - 127.0.0.1
  - apiserver.cluster.local
  - 172.24.20.51
  - 172.24.20.52
  - 172.24.20.53
  - 10.10.10.10
  extraArgs:
    feature-gates: TTLAfterFinished=true
  extraVolumes:
  - name: localtime
    hostPath: /etc/localtime
    mountPath: /etc/localtime
    readOnly: true
    pathType: File
controllerManager:
  extraArgs:
    feature-gates: TTLAfterFinished=true
    experimental-cluster-signing-duration: 876000h
  extraVolumes:
  - hostPath: /etc/localtime
    mountPath: /etc/localtime
    name: localtime
    readOnly: true
    pathType: File
scheduler:
  extraArgs:
    feature-gates: TTLAfterFinished=true
  extraVolumes:
  - hostPath: /etc/localtime
    mountPath: /etc/localtime
    name: localtime
    readOnly: true
    pathType: File
---
apiVersion: kubeproxy.config.k8s.io/v1alpha1
kind: KubeProxyConfiguration
mode: &#34;ipvs&#34;
ipvs:
  excludeCIDRs:
  - &#34;10.10.10.10/32&#34;&#34; &gt; /root/kubeadm-config.yaml
06:52:53 [DEBG] [print.go:21] ==&gt;SendPackage==&gt;KubeadmConfigInstall
06:52:53 [INFO] [ssh.go:13] [ssh][172.24.20.51:22] hostname
06:52:54 [DEBG] [ssh.go:25] [ssh][172.24.20.51:22]command result is: cloudos-51

06:52:54 [INFO] [kube_certs.go:223] apiserver altNames : {map[apiserver.cluster.local:apiserver.cluster.local cloudos-51:cloudos-51 kubernetes:kubernetes kubernetes.default:kubernetes.default kubernetes.default.svc:kubernetes.default.svc kubernetes.default.svc.cluster.local:kubernetes.default.svc.cluster.local localhost:localhost] map[10.10.10.10:10.10.10.10 10.40.0.1:10.40.0.1 127.0.0.1:127.0.0.1 172.24.20.51:172.24.20.51 172.24.20.52:172.24.20.52 172.24.20.53:172.24.20.53]}
06:52:54 [INFO] [kube_certs.go:243] Etcd altnames : {map[cloudos-51:cloudos-51 localhost:localhost] map[127.0.0.1:127.0.0.1 172.24.20.51:172.24.20.51 ::1:::1]}, commonName : cloudos-51
06:52:58 [INFO] [ssh.go:13] [ssh][172.24.20.51:22] hostname
06:52:58 [DEBG] [ssh.go:25] [ssh][172.24.20.51:22]command result is: cloudos-51

[kubeconfig] Writing &#34;admin.conf&#34; kubeconfig file
[kubeconfig] Writing &#34;controller-manager.conf&#34; kubeconfig file
[kubeconfig] Writing &#34;scheduler.conf&#34; kubeconfig file
[kubeconfig] Writing &#34;kubelet.conf&#34; kubeconfig file
06:53:00 [DEBG] [ssh.go:58] [172.24.20.51:22] mkdir -p /etc/kubernetes || true
06:53:00 [DEBG] [scp.go:337] [ssh][172.24.20.51:22]transfer local [/root/.sealos/kubelet.conf] to Dst [/etc/kubernetes/kubelet.conf] total size is: 5.48KB ;speed is 5KB
06:53:01 [DEBG] [ssh.go:58] [172.24.20.51:22] mkdir -p /etc/kubernetes || true
06:53:02 [DEBG] [scp.go:337] [ssh][172.24.20.51:22]transfer local [/root/.sealos/admin.conf] to Dst [/etc/kubernetes/admin.conf] total size is: 5.46KB ;speed is 5KB
06:53:03 [DEBG] [ssh.go:58] [172.24.20.51:22] mkdir -p /etc/kubernetes || true
06:53:04 [DEBG] [scp.go:337] [ssh][172.24.20.51:22]transfer local [/root/.sealos/controller-manager.conf] to Dst [/etc/kubernetes/controller-manager.conf] total size is: 5.49KB ;speed is 5KB
06:53:05 [DEBG] [ssh.go:58] [172.24.20.51:22] mkdir -p /etc/kubernetes || true
06:53:05 [DEBG] [scp.go:337] [ssh][172.24.20.51:22]transfer local [/root/.sealos/scheduler.conf] to Dst [/etc/kubernetes/scheduler.conf] total size is: 5.44KB ;speed is 5KB
06:53:06 [DEBG] [scp.go:337] [ssh][172.24.20.51:22]transfer local [/root/.sealos/pki/apiserver-etcd-client.crt] to Dst [/etc/kubernetes/pki/apiserver-etcd-client.crt] total size is: 1.11KB ;speed is 1KB
06:53:07 [DEBG] [scp.go:337] [ssh][172.24.20.51:22]transfer local [/root/.sealos/pki/apiserver-etcd-client.key] to Dst [/etc/kubernetes/pki/apiserver-etcd-client.key] total size is: 1.64KB ;speed is 1KB
06:53:08 [DEBG] [scp.go:337] [ssh][172.24.20.51:22]transfer local [/root/.sealos/pki/apiserver-kubelet-client.crt] to Dst [/etc/kubernetes/pki/apiserver-kubelet-client.crt] total size is: 1.12KB ;speed is 1KB
06:53:09 [DEBG] [scp.go:337] [ssh][172.24.20.51:22]transfer local [/root/.sealos/pki/apiserver-kubelet-client.key] to Dst [/etc/kubernetes/pki/apiserver-kubelet-client.key] total size is: 1.64KB ;speed is 1KB
06:53:09 [DEBG] [scp.go:337] [ssh][172.24.20.51:22]transfer local [/root/.sealos/pki/apiserver.crt] to Dst [/etc/kubernetes/pki/apiserver.crt] total size is: 1.33KB ;speed is 1KB
06:53:09 [DEBG] [scp.go:337] [ssh][172.24.20.51:22]transfer local [/root/.sealos/pki/apiserver.key] to Dst [/etc/kubernetes/pki/apiserver.key] total size is: 1.64KB ;speed is 1KB
06:53:10 [DEBG] [scp.go:337] [ssh][172.24.20.51:22]transfer local [/root/.sealos/pki/ca.crt] to Dst [/etc/kubernetes/pki/ca.crt] total size is: 1.04KB ;speed is 1KB
06:53:10 [DEBG] [scp.go:337] [ssh][172.24.20.51:22]transfer local [/root/.sealos/pki/ca.key] to Dst [/etc/kubernetes/pki/ca.key] total size is: 1.64KB ;speed is 1KB
06:53:10 [DEBG] [scp.go:337] [ssh][172.24.20.51:22]transfer local [/root/.sealos/pki/etcd/ca.crt] to Dst [/etc/kubernetes/pki/etcd/ca.crt] total size is: 1.04KB ;speed is 1KB
06:53:11 [DEBG] [scp.go:337] [ssh][172.24.20.51:22]transfer local [/root/.sealos/pki/etcd/ca.key] to Dst [/etc/kubernetes/pki/etcd/ca.key] total size is: 1.64KB ;speed is 1KB
06:53:11 [DEBG] [scp.go:337] [ssh][172.24.20.51:22]transfer local [/root/.sealos/pki/etcd/healthcheck-client.crt] to Dst [/etc/kubernetes/pki/etcd/healthcheck-client.crt] total size is: 1.12KB ;speed is 1KB
06:53:12 [DEBG] [scp.go:337] [ssh][172.24.20.51:22]transfer local [/root/.sealos/pki/etcd/healthcheck-client.key] to Dst [/etc/kubernetes/pki/etcd/healthcheck-client.key] total size is: 1.64KB ;speed is 1KB
06:53:12 [DEBG] [scp.go:337] [ssh][172.24.20.51:22]transfer local [/root/.sealos/pki/etcd/peer.crt] to Dst [/etc/kubernetes/pki/etcd/peer.crt] total size is: 1.16KB ;speed is 1KB
06:53:13 [DEBG] [scp.go:337] [ssh][172.24.20.51:22]transfer local [/root/.sealos/pki/etcd/peer.key] to Dst [/etc/kubernetes/pki/etcd/peer.key] total size is: 1.64KB ;speed is 1KB
06:53:13 [DEBG] [scp.go:337] [ssh][172.24.20.51:22]transfer local [/root/.sealos/pki/etcd/server.crt] to Dst [/etc/kubernetes/pki/etcd/server.crt] total size is: 1.16KB ;speed is 1KB
06:53:13 [DEBG] [scp.go:337] [ssh][172.24.20.51:22]transfer local [/root/.sealos/pki/etcd/server.key] to Dst [/etc/kubernetes/pki/etcd/server.key] total size is: 1.64KB ;speed is 1KB
06:53:14 [DEBG] [scp.go:337] [ssh][172.24.20.51:22]transfer local [/root/.sealos/pki/front-proxy-ca.crt] to Dst [/etc/kubernetes/pki/front-proxy-ca.crt] total size is: 1.06KB ;speed is 1KB
06:53:14 [DEBG] [scp.go:337] [ssh][172.24.20.51:22]transfer local [/root/.sealos/pki/front-proxy-ca.key] to Dst [/etc/kubernetes/pki/front-proxy-ca.key] total size is: 1.64KB ;speed is 1KB
06:53:14 [DEBG] [scp.go:337] [ssh][172.24.20.51:22]transfer local [/root/.sealos/pki/front-proxy-client.crt] to Dst [/etc/kubernetes/pki/front-proxy-client.crt] total size is: 1.08KB ;speed is 1KB
06:53:15 [DEBG] [scp.go:337] [ssh][172.24.20.51:22]transfer local [/root/.sealos/pki/front-proxy-client.key] to Dst [/etc/kubernetes/pki/front-proxy-client.key] total size is: 1.64KB ;speed is 1KB
06:53:15 [DEBG] [scp.go:337] [ssh][172.24.20.51:22]transfer local [/root/.sealos/pki/sa.key] to Dst [/etc/kubernetes/pki/sa.key] total size is: 1.64KB ;speed is 1KB
06:53:15 [DEBG] [scp.go:337] [ssh][172.24.20.51:22]transfer local [/root/.sealos/pki/sa.pub] to Dst [/etc/kubernetes/pki/sa.pub] total size is: 0.44KB ;speed is 0KB
06:53:16 [DEBG] [ssh.go:58] [172.24.20.51:22] grep -qF &#39;172.24.20.51 apiserver.cluster.local&#39; /etc/hosts || echo 172.24.20.51 apiserver.cluster.local &gt;&gt; /etc/hosts
06:53:18 [INFO] [ssh.go:13] [ssh][172.24.20.51:22] kubeadm init --config=/root/kubeadm-config.yaml --upload-certs -v 0
06:53:49 [DEBG] [ssh.go:25] [ssh][172.24.20.51:22]command result is: W0609 06:53:19.184294    4607 common.go:77] your configuration file uses a deprecated API spec: &#34;kubeadm.k8s.io/v1beta1&#34;. Please use &#39;kubeadm config migrate --old-config old.yaml --new-config new.yaml&#39;, which will write the new, similar spec using a newer API version.
W0609 06:53:19.187726    4607 common.go:77] your configuration file uses a deprecated API spec: &#34;kubeadm.k8s.io/v1beta1&#34;. Please use &#39;kubeadm config migrate --old-config old.yaml --new-config new.yaml&#39;, which will write the new, similar spec using a newer API version.
W0609 06:53:19.475223    4607 configset.go:348] WARNING: kubeadm cannot validate component configs for API groups [kubelet.config.k8s.io kubeproxy.config.k8s.io]
[init] Using Kubernetes version: v1.19.0
[preflight] Running pre-flight checks
        [WARNING IsDockerSystemdCheck]: detected &#34;cgroupfs&#34; as the Docker cgroup driver. The recommended driver is &#34;systemd&#34;. Please follow the guide at https://kubernetes.io/docs/setup/cri/
        [WARNING FileExisting-socat]: socat not found in system path
        [WARNING FileExisting-tc]: tc not found in system path
[preflight] Pulling images required for setting up a Kubernetes cluster
[preflight] This might take a minute or two, depending on the speed of your internet connection
[preflight] You can also perform this action in beforehand using &#39;kubeadm config images pull&#39;
[certs] Using certificateDir folder &#34;/etc/kubernetes/pki&#34;
[certs] Using existing ca certificate authority
[certs] Using existing apiserver certificate and key on disk
[certs] Using existing apiserver-kubelet-client certificate and key on disk
[certs] Using existing front-proxy-ca certificate authority
[certs] Using existing front-proxy-client certificate and key on disk
[certs] Using existing etcd/ca certificate authority
[certs] Using existing etcd/server certificate and key on disk
[certs] Using existing etcd/peer certificate and key on disk
[certs] Using existing etcd/healthcheck-client certificate and key on disk
[certs] Using existing apiserver-etcd-client certificate and key on disk
[certs] Using the existing &#34;sa&#34; key
[kubeconfig] Using kubeconfig folder &#34;/etc/kubernetes&#34;
[kubeconfig] Using existing kubeconfig file: &#34;/etc/kubernetes/admin.conf&#34;
[kubeconfig] Using existing kubeconfig file: &#34;/etc/kubernetes/kubelet.conf&#34;
[kubeconfig] Using existing kubeconfig file: &#34;/etc/kubernetes/controller-manager.conf&#34;
[kubeconfig] Using existing kubeconfig file: &#34;/etc/kubernetes/scheduler.conf&#34;
[kubelet-start] Writing kubelet environment file with flags to file &#34;/var/lib/kubelet/kubeadm-flags.env&#34;
[kubelet-start] Writing kubelet configuration to file &#34;/var/lib/kubelet/config.yaml&#34;
[kubelet-start] Starting the kubelet
[control-plane] Using manifest folder &#34;/etc/kubernetes/manifests&#34;
[control-plane] Creating static Pod manifest for &#34;kube-apiserver&#34;
[control-plane] Creating static Pod manifest for &#34;kube-controller-manager&#34;
[control-plane] Creating static Pod manifest for &#34;kube-scheduler&#34;
[etcd] Creating static Pod manifest for local etcd in &#34;/etc/kubernetes/manifests&#34;
[wait-control-plane] Waiting for the kubelet to boot up the control plane as static Pods from directory &#34;/etc/kubernetes/manifests&#34;. This can take up to 4m0s
[apiclient] All control plane components are healthy after 24.509231 seconds
[upload-config] Storing the configuration used in ConfigMap &#34;kubeadm-config&#34; in the &#34;kube-system&#34; Namespace
[kubelet] Creating a ConfigMap &#34;kubelet-config-1.19&#34; in namespace kube-system with the configuration for the kubelets in the cluster
[upload-certs] Storing the certificates in Secret &#34;kubeadm-certs&#34; in the &#34;kube-system&#34; Namespace
[upload-certs] Using certificate key:
53536c5a0d142e6dbbc178f5c132f918d9c83088c6d1c9f54800467cdf054eee
[mark-control-plane] Marking the node cloudos-51 as control-plane by adding the label &#34;node-role.kubernetes.io/master=&#39;&#39;&#34;
[mark-control-plane] Marking the node cloudos-51 as control-plane by adding the taints [node-role.kubernetes.io/master:NoSchedule]
[bootstrap-token] Using token: 7tfbyw.qgkimu2s8z4wq3fh
[bootstrap-token] Configuring bootstrap tokens, cluster-info ConfigMap, RBAC Roles
[bootstrap-token] configured RBAC rules to allow Node Bootstrap tokens to get nodes
[bootstrap-token] configured RBAC rules to allow Node Bootstrap tokens to post CSRs in order for nodes to get long term certificate credentials
[bootstrap-token] configured RBAC rules to allow the csrapprover controller automatically approve CSRs from a Node Bootstrap Token
[bootstrap-token] configured RBAC rules to allow certificate rotation for all node client certificates in the cluster
[bootstrap-token] Creating the &#34;cluster-info&#34; ConfigMap in the &#34;kube-public&#34; namespace
[kubelet-finalize] Updating &#34;/etc/kubernetes/kubelet.conf&#34; to point to a rotatable kubelet client certificate and key
[addons] Applied essential addon: CoreDNS
[addons] Applied essential addon: kube-proxy

Your Kubernetes control-plane has initialized successfully!

To start using your cluster, you need to run the following as a regular user:

  mkdir -p $HOME/.kube
  sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config
  sudo chown $(id -u):$(id -g) $HOME/.kube/config

You should now deploy a pod network to the cluster.
Run &#34;kubectl apply -f [podnetwork].yaml&#34; with one of the options listed at:
  https://kubernetes.io/docs/concepts/cluster-administration/addons/

You can now join any number of the control-plane node running the following command on each as root:

  kubeadm join apiserver.cluster.local:6443 --token 7tfbyw.qgkimu2s8z4wq3fh \
    --discovery-token-ca-cert-hash sha256:495a8e10ba234a29e827960e1b985e326bd27471631396b6c4b26084796b8567 \
    --control-plane --certificate-key 53536c5a0d142e6dbbc178f5c132f918d9c83088c6d1c9f54800467cdf054eee

Please note that the certificate-key gives access to cluster sensitive data, keep it secret!
As a safeguard, uploaded-certs will be deleted in two hours; If necessary, you can use
&#34;kubeadm init phase upload-certs --upload-certs&#34; to reload certs afterward.

Then you can join any number of worker nodes by running the following on each as root:

kubeadm join apiserver.cluster.local:6443 --token 7tfbyw.qgkimu2s8z4wq3fh \
    --discovery-token-ca-cert-hash sha256:495a8e10ba234a29e827960e1b985e326bd27471631396b6c4b26084796b8567 

06:53:49 [DEBG] [sealos.go:102] [globals]decodeOutput: W0609 06:53:19.184294    4607 common.go:77] your configuration file uses a deprecated API spec: &#34;kubeadm.k8s.io/v1beta1&#34;. Please use &#39;kubeadm config migrate --old-config old.yaml --new-config new.yaml&#39;, which will write the new, similar spec using a newer API version.
W0609 06:53:19.187726    4607 common.go:77] your configuration file uses a deprecated API spec: &#34;kubeadm.k8s.io/v1beta1&#34;. Please use &#39;kubeadm config migrate --old-config old.yaml --new-config new.yaml&#39;, which will write the new, similar spec using a newer API version.
W0609 06:53:19.475223    4607 configset.go:348] WARNING: kubeadm cannot validate component configs for API groups [kubelet.config.k8s.io kubeproxy.config.k8s.io]
[init] Using Kubernetes version: v1.19.0
[preflight] Running pre-flight checks
        [WARNING IsDockerSystemdCheck]: detected &#34;cgroupfs&#34; as the Docker cgroup driver. The recommended driver is &#34;systemd&#34;. Please follow the guide at https://kubernetes.io/docs/setup/cri/
        [WARNING FileExisting-socat]: socat not found in system path
        [WARNING FileExisting-tc]: tc not found in system path
[preflight] Pulling images required for setting up a Kubernetes cluster
[preflight] This might take a minute or two, depending on the speed of your internet connection
[preflight] You can also perform this action in beforehand using &#39;kubeadm config images pull&#39;
[certs] Using certificateDir folder &#34;/etc/kubernetes/pki&#34;
[certs] Using existing ca certificate authority
[certs] Using existing apiserver certificate and key on disk
[certs] Using existing apiserver-kubelet-client certificate and key on disk
[certs] Using existing front-proxy-ca certificate authority
[certs] Using existing front-proxy-client certificate and key on disk
[certs] Using existing etcd/ca certificate authority
[certs] Using existing etcd/server certificate and key on disk
[certs] Using existing etcd/peer certificate and key on disk
[certs] Using existing etcd/healthcheck-client certificate and key on disk
[certs] Using existing apiserver-etcd-client certificate and key on disk
[certs] Using the existing &#34;sa&#34; key
[kubeconfig] Using kubeconfig folder &#34;/etc/kubernetes&#34;
[kubeconfig] Using existing kubeconfig file: &#34;/etc/kubernetes/admin.conf&#34;
[kubeconfig] Using existing kubeconfig file: &#34;/etc/kubernetes/kubelet.conf&#34;
[kubeconfig] Using existing kubeconfig file: &#34;/etc/kubernetes/controller-manager.conf&#34;
[kubeconfig] Using existing kubeconfig file: &#34;/etc/kubernetes/scheduler.conf&#34;
[kubelet-start] Writing kubelet environment file with flags to file &#34;/var/lib/kubelet/kubeadm-flags.env&#34;
[kubelet-start] Writing kubelet configuration to file &#34;/var/lib/kubelet/config.yaml&#34;
[kubelet-start] Starting the kubelet
[control-plane] Using manifest folder &#34;/etc/kubernetes/manifests&#34;
[control-plane] Creating static Pod manifest for &#34;kube-apiserver&#34;
[control-plane] Creating static Pod manifest for &#34;kube-controller-manager&#34;
[control-plane] Creating static Pod manifest for &#34;kube-scheduler&#34;
[etcd] Creating static Pod manifest for local etcd in &#34;/etc/kubernetes/manifests&#34;
[wait-control-plane] Waiting for the kubelet to boot up the control plane as static Pods from directory &#34;/etc/kubernetes/manifests&#34;. This can take up to 4m0s
[apiclient] All control plane components are healthy after 24.509231 seconds
[upload-config] Storing the configuration used in ConfigMap &#34;kubeadm-config&#34; in the &#34;kube-system&#34; Namespace
[kubelet] Creating a ConfigMap &#34;kubelet-config-1.19&#34; in namespace kube-system with the configuration for the kubelets in the cluster
[upload-certs] Storing the certificates in Secret &#34;kubeadm-certs&#34; in the &#34;kube-system&#34; Namespace
[upload-certs] Using certificate key:
53536c5a0d142e6dbbc178f5c132f918d9c83088c6d1c9f54800467cdf054eee
[mark-control-plane] Marking the node cloudos-51 as control-plane by adding the label &#34;node-role.kubernetes.io/master=&#39;&#39;&#34;
[mark-control-plane] Marking the node cloudos-51 as control-plane by adding the taints [node-role.kubernetes.io/master:NoSchedule]
[bootstrap-token] Using token: 7tfbyw.qgkimu2s8z4wq3fh
[bootstrap-token] Configuring bootstrap tokens, cluster-info ConfigMap, RBAC Roles
[bootstrap-token] configured RBAC rules to allow Node Bootstrap tokens to get nodes
[bootstrap-token] configured RBAC rules to allow Node Bootstrap tokens to post CSRs in order for nodes to get long term certificate credentials
[bootstrap-token] configured RBAC rules to allow the csrapprover controller automatically approve CSRs from a Node Bootstrap Token
[bootstrap-token] configured RBAC rules to allow certificate rotation for all node client certificates in the cluster
[bootstrap-token] Creating the &#34;cluster-info&#34; ConfigMap in the &#34;kube-public&#34; namespace
[kubelet-finalize] Updating &#34;/etc/kubernetes/kubelet.conf&#34; to point to a rotatable kubelet client certificate and key
[addons] Applied essential addon: CoreDNS
[addons] Applied essential addon: kube-proxy

Your Kubernetes control-plane has initialized successfully!

To start using your cluster, you need to run the following as a regular user:

  mkdir -p $HOME/.kube
  sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config
  sudo chown $(id -u):$(id -g) $HOME/.kube/config

You should now deploy a pod network to the cluster.
Run &#34;kubectl apply -f [podnetwork].yaml&#34; with one of the options listed at:
  https://kubernetes.io/docs/concepts/cluster-administration/addons/

You can now join any number of the control-plane node running the following command on each as root:

  kubeadm join apiserver.cluster.local:6443 --token 7tfbyw.qgkimu2s8z4wq3fh \
    --discovery-token-ca-cert-hash sha256:495a8e10ba234a29e827960e1b985e326bd27471631396b6c4b26084796b8567 \
    --control-plane --certificate-key 53536c5a0d142e6dbbc178f5c132f918d9c83088c6d1c9f54800467cdf054eee

Please note that the certificate-key gives access to cluster sensitive data, keep it secret!
As a safeguard, uploaded-certs will be deleted in two hours; If necessary, you can use
&#34;kubeadm init phase upload-certs --upload-certs&#34; to reload certs afterward.

Then you can join any number of worker nodes by running the following on each as root:

kubeadm join apiserver.cluster.local:6443 --token 7tfbyw.qgkimu2s8z4wq3fh \
    --discovery-token-ca-cert-hash sha256:495a8e10ba234a29e827960e1b985e326bd27471631396b6c4b26084796b8567 

06:53:49 [INFO] [sealos.go:105] [globals]join command is:  apiserver.cluster.local:6443 --token 7tfbyw.qgkimu2s8z4wq3fh \
    --discovery-token-ca-cert-hash sha256:495a8e10ba234a29e827960e1b985e326bd27471631396b6c4b26084796b8567 \
    --control-plane --certificate-key 53536c5a0d142e6dbbc178f5c132f918d9c83088c6d1c9f54800467cdf054eee


06:53:49 [DEBG] [sealos.go:111] [globals]decodeJoinCmd:  apiserver.cluster.local:6443 --token 7tfbyw.qgkimu2s8z4wq3fh \
    --discovery-token-ca-cert-hash sha256:495a8e10ba234a29e827960e1b985e326bd27471631396b6c4b26084796b8567 \
    --control-plane --certificate-key 53536c5a0d142e6dbbc178f5c132f918d9c83088c6d1c9f54800467cdf054eee


06:53:49 [DEBG] [sealos.go:119] [####]0 ::
06:53:49 [DEBG] [sealos.go:119] [####]1 :apiserver.cluster.local:6443:
06:53:49 [DEBG] [sealos.go:119] [####]2 :--token:
06:53:49 [DEBG] [sealos.go:119] [####]3 :7tfbyw.qgkimu2s8z4wq3fh:
06:53:49 [DEBG] [sealos.go:119] [####]4 ::
06:53:49 [DEBG] [sealos.go:119] [####]5 ::
06:53:49 [DEBG] [sealos.go:119] [####]6 ::
06:53:49 [DEBG] [sealos.go:119] [####]7 ::
06:53:49 [DEBG] [sealos.go:119] [####]8 :--discovery-token-ca-cert-hash:
06:53:49 [DEBG] [sealos.go:119] [####]9 :sha256:495a8e10ba234a29e827960e1b985e326bd27471631396b6c4b26084796b8567:
06:53:49 [DEBG] [sealos.go:119] [####]10 ::
06:53:49 [DEBG] [sealos.go:119] [####]11 ::
06:53:49 [DEBG] [sealos.go:119] [####]12 ::
06:53:49 [DEBG] [sealos.go:119] [####]13 ::
06:53:49 [DEBG] [sealos.go:119] [####]14 :--control-plane:
06:53:49 [DEBG] [sealos.go:119] [####]15 :--certificate-key:
06:53:49 [DEBG] [sealos.go:119] [####]16 :53536c5a0d142e6dbbc178f5c132f918d9c83088c6d1c9f54800467cdf054eee:
06:53:49 [DEBG] [sealos.go:140] [####]JoinToken :7tfbyw.qgkimu2s8z4wq3fh
06:53:49 [DEBG] [sealos.go:141] [####]TokenCaCertHash :sha256:495a8e10ba234a29e827960e1b985e326bd27471631396b6c4b26084796b8567
06:53:49 [DEBG] [sealos.go:142] [####]CertificateKey :53536c5a0d142e6dbbc178f5c132f918d9c83088c6d1c9f54800467cdf054eee
06:53:49 [INFO] [ssh.go:13] [ssh][172.24.20.51:22] mkdir -p /root/.kube &amp;&amp; cp /etc/kubernetes/admin.conf /root/.kube/config &amp;&amp; chmod 600 /root/.kube/config
06:53:50 [DEBG] [ssh.go:25] [ssh][172.24.20.51:22]command result is: 
06:53:50 [INFO] [ssh.go:13] [ssh][172.24.20.51:22] echo &#39;
---
# Source: calico/templates/calico-config.yaml
# This ConfigMap is used to configure a self-hosted Calico installation.
kind: ConfigMap
apiVersion: v1
metadata:
  name: calico-config
  namespace: kube-system
data:
  # Typha is disabled.
  typha_service_name: &#34;none&#34;
  # Configure the backend to use.
  calico_backend: &#34;bird&#34;

  # Configure the MTU to use
  veth_mtu: &#34;1440&#34;

  # The CNI network configuration to install on each node.  The special
  # values in this config will be automatically populated.
  cni_network_config: |-
    {
      &#34;name&#34;: &#34;k8s-pod-network&#34;,
      &#34;cniVersion&#34;: &#34;0.3.1&#34;,
      &#34;plugins&#34;: [
        {
          &#34;type&#34;: &#34;calico&#34;,
          &#34;log_level&#34;: &#34;info&#34;,
          &#34;datastore_type&#34;: &#34;kubernetes&#34;,
          &#34;nodename&#34;: &#34;__KUBERNETES_NODE_NAME__&#34;,
          &#34;mtu&#34;: __CNI_MTU__,
          &#34;ipam&#34;: {
              &#34;type&#34;: &#34;calico-ipam&#34;
          },
          &#34;policy&#34;: {
              &#34;type&#34;: &#34;k8s&#34;
          },
          &#34;kubernetes&#34;: {
              &#34;kubeconfig&#34;: &#34;__KUBECONFIG_FILEPATH__&#34;
          }
        },
        {
          &#34;type&#34;: &#34;portmap&#34;,
          &#34;snat&#34;: true,
          &#34;capabilities&#34;: {&#34;portMappings&#34;: true}
        }
      ]
    }
---
# Source: calico/templates/kdd-crds.yaml
apiVersion: apiextensions.k8s.io/v1beta1
kind: CustomResourceDefinition
metadata:
   name: felixconfigurations.crd.projectcalico.org
spec:
  scope: Cluster
  group: crd.projectcalico.org
  version: v1
  names:
    kind: FelixConfiguration
    plural: felixconfigurations
    singular: felixconfiguration
---

apiVersion: apiextensions.k8s.io/v1beta1
kind: CustomResourceDefinition
metadata:
  name: ipamblocks.crd.projectcalico.org
spec:
  scope: Cluster
  group: crd.projectcalico.org
  version: v1
  names:
    kind: IPAMBlock
    plural: ipamblocks
    singular: ipamblock

---

apiVersion: apiextensions.k8s.io/v1beta1
kind: CustomResourceDefinition
metadata:
  name: blockaffinities.crd.projectcalico.org
spec:
  scope: Cluster
  group: crd.projectcalico.org
  version: v1
  names:
    kind: BlockAffinity
    plural: blockaffinities
    singular: blockaffinity

---

apiVersion: apiextensions.k8s.io/v1beta1
kind: CustomResourceDefinition
metadata:
  name: ipamhandles.crd.projectcalico.org
spec:
  scope: Cluster
  group: crd.projectcalico.org
  version: v1
  names:
    kind: IPAMHandle
    plural: ipamhandles
    singular: ipamhandle

---

apiVersion: apiextensions.k8s.io/v1beta1
kind: CustomResourceDefinition
metadata:
  name: ipamconfigs.crd.projectcalico.org
spec:
  scope: Cluster
  group: crd.projectcalico.org
  version: v1
  names:
    kind: IPAMConfig
    plural: ipamconfigs
    singular: ipamconfig

---

apiVersion: apiextensions.k8s.io/v1beta1
kind: CustomResourceDefinition
metadata:
  name: bgppeers.crd.projectcalico.org
spec:
  scope: Cluster
  group: crd.projectcalico.org
  version: v1
  names:
    kind: BGPPeer
    plural: bgppeers
    singular: bgppeer

---

apiVersion: apiextensions.k8s.io/v1beta1
kind: CustomResourceDefinition
metadata:
  name: bgpconfigurations.crd.projectcalico.org
spec:
  scope: Cluster
  group: crd.projectcalico.org
  version: v1
  names:
    kind: BGPConfiguration
    plural: bgpconfigurations
    singular: bgpconfiguration

---

apiVersion: apiextensions.k8s.io/v1beta1
kind: CustomResourceDefinition
metadata:
  name: ippools.crd.projectcalico.org
spec:
  scope: Cluster
  group: crd.projectcalico.org
  version: v1
  names:
    kind: IPPool
    plural: ippools
    singular: ippool

---

apiVersion: apiextensions.k8s.io/v1beta1
kind: CustomResourceDefinition
metadata:
  name: hostendpoints.crd.projectcalico.org
spec:
  scope: Cluster
  group: crd.projectcalico.org
  version: v1
  names:
    kind: HostEndpoint
    plural: hostendpoints
    singular: hostendpoint

---

apiVersion: apiextensions.k8s.io/v1beta1
kind: CustomResourceDefinition
metadata:
  name: clusterinformations.crd.projectcalico.org
spec:
  scope: Cluster
  group: crd.projectcalico.org
  version: v1
  names:
    kind: ClusterInformation
    plural: clusterinformations
    singular: clusterinformation

---

apiVersion: apiextensions.k8s.io/v1beta1
kind: CustomResourceDefinition
metadata:
  name: globalnetworkpolicies.crd.projectcalico.org
spec:
  scope: Cluster
  group: crd.projectcalico.org
  version: v1
  names:
    kind: GlobalNetworkPolicy
    plural: globalnetworkpolicies
    singular: globalnetworkpolicy

---

apiVersion: apiextensions.k8s.io/v1beta1
kind: CustomResourceDefinition
metadata:
  name: globalnetworksets.crd.projectcalico.org
spec:
  scope: Cluster
  group: crd.projectcalico.org
  version: v1
  names:
    kind: GlobalNetworkSet
    plural: globalnetworksets
    singular: globalnetworkset

---

apiVersion: apiextensions.k8s.io/v1beta1
kind: CustomResourceDefinition
metadata:
  name: networkpolicies.crd.projectcalico.org
spec:
  scope: Namespaced
  group: crd.projectcalico.org
  version: v1
  names:
    kind: NetworkPolicy
    plural: networkpolicies
    singular: networkpolicy

---

apiVersion: apiextensions.k8s.io/v1beta1
kind: CustomResourceDefinition
metadata:
  name: networksets.crd.projectcalico.org
spec:
  scope: Namespaced
  group: crd.projectcalico.org
  version: v1
  names:
    kind: NetworkSet
    plural: networksets
    singular: networkset
---
# Source: calico/templates/rbac.yaml

# Include a clusterrole for the kube-controllers component,
# and bind it to the calico-kube-controllers serviceaccount.
kind: ClusterRole
apiVersion: rbac.authorization.k8s.io/v1
metadata:
  name: calico-kube-controllers
rules:
  # Nodes are watched to monitor for deletions.
  - apiGroups: [&#34;&#34;]
    resources:
      - nodes
    verbs:
      - watch
      - list
      - get
  # Pods are queried to check for existence.
  - apiGroups: [&#34;&#34;]
    resources:
      - pods
    verbs:
      - get
  # IPAM resources are manipulated when nodes are deleted.
  - apiGroups: [&#34;crd.projectcalico.org&#34;]
    resources:
      - ippools
    verbs:
      - list
  - apiGroups: [&#34;crd.projectcalico.org&#34;]
    resources:
      - blockaffinities
      - ipamblocks
      - ipamhandles
    verbs:
      - get
      - list
      - create
      - update
      - delete
  # Needs access to update clusterinformations.
  - apiGroups: [&#34;crd.projectcalico.org&#34;]
    resources:
      - clusterinformations
    verbs:
      - get
      - create
      - update
---
kind: ClusterRoleBinding
apiVersion: rbac.authorization.k8s.io/v1
metadata:
  name: calico-kube-controllers
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: calico-kube-controllers
subjects:
- kind: ServiceAccount
  name: calico-kube-controllers
  namespace: kube-system
---
# Include a clusterrole for the calico-node DaemonSet,
# and bind it to the calico-node serviceaccount.
kind: ClusterRole
apiVersion: rbac.authorization.k8s.io/v1
metadata:
  name: calico-node
rules:
  # The CNI plugin needs to get pods, nodes, and namespaces.
  - apiGroups: [&#34;&#34;]
    resources:
      - pods
      - nodes
      - namespaces
    verbs:
      - get
  - apiGroups: [&#34;&#34;]
    resources:
      - endpoints
      - services
    verbs:
      # Used to discover service IPs for advertisement.
      - watch
      - list
      # Used to discover Typhas.
      - get
  - apiGroups: [&#34;&#34;]
    resources:
      - nodes/status
    verbs:
      # Needed for clearing NodeNetworkUnavailable flag.
      - patch
      # Calico stores some configuration information in node annotations.
      - update
  # Watch for changes to Kubernetes NetworkPolicies.
  - apiGroups: [&#34;networking.k8s.io&#34;]
    resources:
      - networkpolicies
    verbs:
      - watch
      - list
  # Used by Calico for policy information.
  - apiGroups: [&#34;&#34;]
    resources:
      - pods
      - namespaces
      - serviceaccounts
    verbs:
      - list
      - watch
  # The CNI plugin patches pods/status.
  - apiGroups: [&#34;&#34;]
    resources:
      - pods/status
    verbs:
      - patch
  # Calico monitors various CRDs for config.
  - apiGroups: [&#34;crd.projectcalico.org&#34;]
    resources:
      - globalfelixconfigs
      - felixconfigurations
      - bgppeers
      - globalbgpconfigs
      - bgpconfigurations
      - ippools
      - ipamblocks
      - globalnetworkpolicies
      - globalnetworksets
      - networkpolicies
      - networksets
      - clusterinformations
      - hostendpoints
    verbs:
      - get
      - list
      - watch
  # Calico must create and update some CRDs on startup.
  - apiGroups: [&#34;crd.projectcalico.org&#34;]
    resources:
      - ippools
      - felixconfigurations
      - clusterinformations
    verbs:
      - create
      - update
  # Calico stores some configuration information on the node.
  - apiGroups: [&#34;&#34;]
    resources:
      - nodes
    verbs:
      - get
      - list
      - watch
  # These permissions are only requried for upgrade from v2.6, and can
  # be removed after upgrade or on fresh installations.
  - apiGroups: [&#34;crd.projectcalico.org&#34;]
    resources:
      - bgpconfigurations
      - bgppeers
    verbs:
      - create
      - update
  # These permissions are required for Calico CNI to perform IPAM allocations.
  - apiGroups: [&#34;crd.projectcalico.org&#34;]
    resources:
      - blockaffinities
      - ipamblocks
      - ipamhandles
    verbs:
      - get
      - list
      - create
      - update
      - delete
  - apiGroups: [&#34;crd.projectcalico.org&#34;]
    resources:
      - ipamconfigs
    verbs:
      - get
  # Block affinities must also be watchable by confd for route aggregation.
  - apiGroups: [&#34;crd.projectcalico.org&#34;]
    resources:
      - blockaffinities
    verbs:
      - watch
  # The Calico IPAM migration needs to get daemonsets. These permissions can be
  # removed if not upgrading from an installation using host-local IPAM.
  - apiGroups: [&#34;apps&#34;]
    resources:
      - daemonsets
    verbs:
      - get
---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding
metadata:
  name: calico-node
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: calico-node
subjects:
- kind: ServiceAccount
  name: calico-node
  namespace: kube-system

---
# Source: calico/templates/calico-node.yaml
# This manifest installs the calico-node container, as well
# as the CNI plugins and network config on
# each master and worker node in a Kubernetes cluster.
kind: DaemonSet
apiVersion: apps/v1
metadata:
  name: calico-node
  namespace: kube-system
  labels:
    k8s-app: calico-node
spec:
  selector:
    matchLabels:
      k8s-app: calico-node
  updateStrategy:
    type: RollingUpdate
    rollingUpdate:
      maxUnavailable: 1
  template:
    metadata:
      labels:
        k8s-app: calico-node
      annotations:
        # This, along with the CriticalAddonsOnly toleration below,
        # marks the pod as a critical add-on, ensuring it gets
        # priority scheduling and that its resources are reserved
        # if it ever gets evicted.
    spec:
      nodeSelector:
        beta.kubernetes.io/os: linux
      hostNetwork: true
      tolerations:
        # Make sure calico-node gets scheduled on all nodes.
        - effect: NoSchedule
          operator: Exists
        # Mark the pod as a critical add-on for rescheduling.
        - key: CriticalAddonsOnly
          operator: Exists
        - effect: NoExecute
          operator: Exists
      serviceAccountName: calico-node
      # Minimize downtime during a rolling upgrade or deletion; tell Kubernetes to do a &#34;force
      # deletion&#34;: https://kubernetes.io/docs/concepts/workloads/pods/pod/#termination-of-pods.
      terminationGracePeriodSeconds: 0
      priorityClassName: system-node-critical
      initContainers:
        # This container performs upgrade from host-local IPAM to calico-ipam.
        # It can be deleted if this is a fresh installation, or if you have already
        # upgraded to use calico-ipam.
        - name: upgrade-ipam
          image: calico/cni:v3.8.2
          command: [&#34;/opt/cni/bin/calico-ipam&#34;, &#34;-upgrade&#34;]
          env:
            - name: KUBERNETES_NODE_NAME
              valueFrom:
                fieldRef:
                  fieldPath: spec.nodeName
            - name: CALICO_NETWORKING_BACKEND
              valueFrom:
                configMapKeyRef:
                  name: calico-config
                  key: calico_backend
          volumeMounts:
            - mountPath: /var/lib/cni/networks
              name: host-local-net-dir
            - mountPath: /host/opt/cni/bin
              name: cni-bin-dir
        # This container installs the CNI binaries
        # and CNI network config file on each node.
        - name: install-cni
          image: calico/cni:v3.8.2
          command: [&#34;/install-cni.sh&#34;]
          env:
            # Name of the CNI config file to create.
            - name: CNI_CONF_NAME
              value: &#34;10-calico.conflist&#34;
            # The CNI network config to install on each node.
            - name: CNI_NETWORK_CONFIG
              valueFrom:
                configMapKeyRef:
                  name: calico-config
                  key: cni_network_config
            # Set the hostname based on the k8s node name.
            - name: KUBERNETES_NODE_NAME
              valueFrom:
                fieldRef:
                  fieldPath: spec.nodeName
            # CNI MTU Config variable
            - name: CNI_MTU
              valueFrom:
                configMapKeyRef:
                  name: calico-config
                  key: veth_mtu
            # Prevents the container from sleeping forever.
            - name: SLEEP
              value: &#34;false&#34;
          volumeMounts:
            - mountPath: /host/opt/cni/bin
              name: cni-bin-dir
            - mountPath: /host/etc/cni/net.d
              name: cni-net-dir
        # Adds a Flex Volume Driver that creates a per-pod Unix Domain Socket to allow Dikastes
        # to communicate with Felix over the Policy Sync API.
        - name: flexvol-driver
          image: calico/pod2daemon-flexvol:v3.8.2
          volumeMounts:
          - name: flexvol-driver-host
            mountPath: /host/driver
      containers:
        # Runs calico-node container on each Kubernetes node.  This
        # container programs network policy and routes on each
        # host.
        - name: calico-node
          image: calico/node:v3.8.2
          env:
            # Use Kubernetes API as the backing datastore.
            - name: DATASTORE_TYPE
              value: &#34;kubernetes&#34;
            # Wait for the datastore.
            - name: WAIT_FOR_DATASTORE
              value: &#34;true&#34;
            # Set based on the k8s node name.
            - name: NODENAME
              valueFrom:
                fieldRef:
                  fieldPath: spec.nodeName
            # Choose the backend to use.
            - name: CALICO_NETWORKING_BACKEND
              valueFrom:
                configMapKeyRef:
                  name: calico-config
                  key: calico_backend
            # Cluster type to identify the deployment type
            - name: CLUSTER_TYPE
              value: &#34;k8s,bgp&#34;
            # Auto-detect the BGP IP address.
            - name: IP
              value: &#34;autodetect&#34;
            - name: IP_AUTODETECTION_METHOD
              value: &#34;interface=eth.*|en.*|em.*&#34;
            # Enable IPIP
            - name: CALICO_IPV4POOL_IPIP
              value: &#34;Always&#34;
            # Set MTU for tunnel device used if ipip is enabled
            - name: FELIX_IPINIPMTU
              valueFrom:
                configMapKeyRef:
                  name: calico-config
                  key: veth_mtu
            # The default IPv4 pool to create on startup if none exists. Pod IPs will be
            # chosen from this range. Changing this value after installation will have
            - name: CALICO_IPV4POOL_CIDR
              value: &#34;10.20.0.0/16&#34;
            - name: CALICO_DISABLE_FILE_LOGGING
              value: &#34;true&#34;
            # Set Felix endpoint to host default action to ACCEPT.
            - name: FELIX_DEFAULTENDPOINTTOHOSTACTION
              value: &#34;ACCEPT&#34;
            # Disable IPv6 on Kubernetes.
            - name: FELIX_IPV6SUPPORT
              value: &#34;false&#34;
            # Set Felix logging to &#34;info&#34;
            - name: FELIX_LOGSEVERITYSCREEN
              value: &#34;info&#34;
            - name: FELIX_HEALTHENABLED
              value: &#34;true&#34;
          securityContext:
            privileged: true
          resources:
            requests:
              cpu: 250m
          livenessProbe:
            httpGet:
              path: /liveness
              port: 9099
              host: localhost
            periodSeconds: 10
            initialDelaySeconds: 10
            failureThreshold: 6
          readinessProbe:
            exec:
              command:
              - /bin/calico-node
              - -bird-ready
              - -felix-ready
            periodSeconds: 10
          volumeMounts:
            - mountPath: /lib/modules
              name: lib-modules
              readOnly: true
            - mountPath: /run/xtables.lock
              name: xtables-lock
              readOnly: false
            - mountPath: /var/run/calico
              name: var-run-calico
              readOnly: false
            - mountPath: /var/lib/calico
              name: var-lib-calico
              readOnly: false
            - name: policysync
              mountPath: /var/run/nodeagent
      volumes:
        # Used by calico-node.
        - name: lib-modules
          hostPath:
            path: /lib/modules
        - name: var-run-calico
          hostPath:
            path: /var/run/calico
        - name: var-lib-calico
          hostPath:
            path: /var/lib/calico
        - name: xtables-lock
          hostPath:
            path: /run/xtables.lock
            type: FileOrCreate
        # Used to install CNI.
        - name: cni-bin-dir
          hostPath:
            path: /opt/cni/bin
        - name: cni-net-dir
          hostPath:
            path: /etc/cni/net.d
        # Mount in the directory for host-local IPAM allocations. This is
        # used when upgrading from host-local to calico-ipam, and can be removed
        # if not using the upgrade-ipam init container.
        - name: host-local-net-dir
          hostPath:
            path: /var/lib/cni/networks
        # Used to create per-pod Unix Domain Sockets
        - name: policysync
          hostPath:
            type: DirectoryOrCreate
            path: /var/run/nodeagent
        # Used to install Flex Volume Driver
        - name: flexvol-driver-host
          hostPath:
            type: DirectoryOrCreate
            path: /usr/libexec/kubernetes/kubelet-plugins/volume/exec/nodeagent~uds
---

apiVersion: v1
kind: ServiceAccount
metadata:
  name: calico-node
  namespace: kube-system

---
# Source: calico/templates/calico-kube-controllers.yaml

# See https://github.com/projectcalico/kube-controllers
apiVersion: apps/v1
kind: Deployment
metadata:
  name: calico-kube-controllers
  namespace: kube-system
  labels:
    k8s-app: calico-kube-controllers
spec:
  # The controllers can only have a single active instance.
  replicas: 1
  selector:
    matchLabels:
      k8s-app: calico-kube-controllers
  strategy:
    type: Recreate
  template:
    metadata:
      name: calico-kube-controllers
      namespace: kube-system
      labels:
        k8s-app: calico-kube-controllers
      annotations:
    spec:
      nodeSelector:
        beta.kubernetes.io/os: linux
      tolerations:
        # Mark the pod as a critical add-on for rescheduling.
        - key: CriticalAddonsOnly
          operator: Exists
        - key: node-role.kubernetes.io/master
          effect: NoSchedule
      serviceAccountName: calico-kube-controllers
      priorityClassName: system-cluster-critical
      containers:
        - name: calico-kube-controllers
          image: calico/kube-controllers:v3.8.2
          env:
            # Choose which controllers to run.
            - name: ENABLED_CONTROLLERS
              value: node
            - name: DATASTORE_TYPE
              value: kubernetes
          readinessProbe:
            exec:
              command:
              - /usr/bin/check-status
              - -r

---

apiVersion: v1
kind: ServiceAccount
metadata:
  name: calico-kube-controllers
  namespace: kube-system
&#39; | kubectl apply -f -
06:53:54 [DEBG] [ssh.go:25] [ssh][172.24.20.51:22]command result is: configmap/calico-config created
Warning: apiextensions.k8s.io/v1beta1 CustomResourceDefinition is deprecated in v1.16+, unavailable in v1.22+; use apiextensions.k8s.io/v1 CustomResourceDefinition
customresourcedefinition.apiextensions.k8s.io/felixconfigurations.crd.projectcalico.org created
customresourcedefinition.apiextensions.k8s.io/ipamblocks.crd.projectcalico.org created
customresourcedefinition.apiextensions.k8s.io/blockaffinities.crd.projectcalico.org created
customresourcedefinition.apiextensions.k8s.io/ipamhandles.crd.projectcalico.org created
customresourcedefinition.apiextensions.k8s.io/ipamconfigs.crd.projectcalico.org created
customresourcedefinition.apiextensions.k8s.io/bgppeers.crd.projectcalico.org created
customresourcedefinition.apiextensions.k8s.io/bgpconfigurations.crd.projectcalico.org created
customresourcedefinition.apiextensions.k8s.io/ippools.crd.projectcalico.org created
customresourcedefinition.apiextensions.k8s.io/hostendpoints.crd.projectcalico.org created
customresourcedefinition.apiextensions.k8s.io/clusterinformations.crd.projectcalico.org created
customresourcedefinition.apiextensions.k8s.io/globalnetworkpolicies.crd.projectcalico.org created
customresourcedefinition.apiextensions.k8s.io/globalnetworksets.crd.projectcalico.org created
customresourcedefinition.apiextensions.k8s.io/networkpolicies.crd.projectcalico.org created
customresourcedefinition.apiextensions.k8s.io/networksets.crd.projectcalico.org created
clusterrole.rbac.authorization.k8s.io/calico-kube-controllers created
clusterrolebinding.rbac.authorization.k8s.io/calico-kube-controllers created
clusterrole.rbac.authorization.k8s.io/calico-node created
clusterrolebinding.rbac.authorization.k8s.io/calico-node created
daemonset.apps/calico-node created
serviceaccount/calico-node created
deployment.apps/calico-kube-controllers created
serviceaccount/calico-kube-controllers created

06:53:54 [DEBG] [print.go:21] ==&gt;SendPackage==&gt;KubeadmConfigInstall==&gt;InstallMaster0
06:53:55 [DEBG] [ssh.go:58] [172.24.20.53:22] mkdir -p /etc/kubernetes || true
06:53:55 [DEBG] [ssh.go:58] [172.24.20.52:22] mkdir -p /etc/kubernetes || true
06:53:57 [DEBG] [scp.go:337] [ssh][172.24.20.53:22]transfer local [/root/.sealos/admin.conf] to Dst [/etc/kubernetes/admin.conf] total size is: 5.46KB ;speed is 5KB
06:53:57 [DEBG] [scp.go:337] [ssh][172.24.20.52:22]transfer local [/root/.sealos/admin.conf] to Dst [/etc/kubernetes/admin.conf] total size is: 5.46KB ;speed is 5KB
06:53:58 [DEBG] [ssh.go:58] [172.24.20.53:22] mkdir -p /etc/kubernetes || true
06:53:58 [DEBG] [ssh.go:58] [172.24.20.52:22] mkdir -p /etc/kubernetes || true
06:53:59 [DEBG] [scp.go:337] [ssh][172.24.20.53:22]transfer local [/root/.sealos/controller-manager.conf] to Dst [/etc/kubernetes/controller-manager.conf] total size is: 5.49KB ;speed is 5KB
06:53:59 [DEBG] [scp.go:337] [ssh][172.24.20.52:22]transfer local [/root/.sealos/controller-manager.conf] to Dst [/etc/kubernetes/controller-manager.conf] total size is: 5.49KB ;speed is 5KB
06:54:00 [DEBG] [ssh.go:58] [172.24.20.53:22] mkdir -p /etc/kubernetes || true
06:54:00 [DEBG] [ssh.go:58] [172.24.20.52:22] mkdir -p /etc/kubernetes || true
06:54:01 [DEBG] [scp.go:337] [ssh][172.24.20.53:22]transfer local [/root/.sealos/scheduler.conf] to Dst [/etc/kubernetes/scheduler.conf] total size is: 5.44KB ;speed is 5KB
06:54:01 [DEBG] [scp.go:337] [ssh][172.24.20.52:22]transfer local [/root/.sealos/scheduler.conf] to Dst [/etc/kubernetes/scheduler.conf] total size is: 5.44KB ;speed is 5KB
06:54:02 [DEBG] [scp.go:337] [ssh][172.24.20.53:22]transfer local [/root/.sealos/pki/apiserver-etcd-client.crt] to Dst [/etc/kubernetes/pki/apiserver-etcd-client.crt] total size is: 1.11KB ;speed is 1KB
06:54:02 [DEBG] [scp.go:337] [ssh][172.24.20.52:22]transfer local [/root/.sealos/pki/apiserver-etcd-client.crt] to Dst [/etc/kubernetes/pki/apiserver-etcd-client.crt] total size is: 1.11KB ;speed is 1KB
06:54:03 [DEBG] [scp.go:337] [ssh][172.24.20.53:22]transfer local [/root/.sealos/pki/apiserver-etcd-client.key] to Dst [/etc/kubernetes/pki/apiserver-etcd-client.key] total size is: 1.64KB ;speed is 1KB
06:54:03 [DEBG] [scp.go:337] [ssh][172.24.20.52:22]transfer local [/root/.sealos/pki/apiserver-etcd-client.key] to Dst [/etc/kubernetes/pki/apiserver-etcd-client.key] total size is: 1.64KB ;speed is 1KB
06:54:03 [DEBG] [scp.go:337] [ssh][172.24.20.53:22]transfer local [/root/.sealos/pki/apiserver-kubelet-client.crt] to Dst [/etc/kubernetes/pki/apiserver-kubelet-client.crt] total size is: 1.12KB ;speed is 1KB
06:54:03 [DEBG] [scp.go:337] [ssh][172.24.20.52:22]transfer local [/root/.sealos/pki/apiserver-kubelet-client.crt] to Dst [/etc/kubernetes/pki/apiserver-kubelet-client.crt] total size is: 1.12KB ;speed is 1KB
06:54:04 [DEBG] [scp.go:337] [ssh][172.24.20.53:22]transfer local [/root/.sealos/pki/apiserver-kubelet-client.key] to Dst [/etc/kubernetes/pki/apiserver-kubelet-client.key] total size is: 1.64KB ;speed is 1KB
06:54:04 [DEBG] [scp.go:337] [ssh][172.24.20.52:22]transfer local [/root/.sealos/pki/apiserver-kubelet-client.key] to Dst [/etc/kubernetes/pki/apiserver-kubelet-client.key] total size is: 1.64KB ;speed is 1KB
06:54:04 [DEBG] [scp.go:337] [ssh][172.24.20.53:22]transfer local [/root/.sealos/pki/apiserver.crt] to Dst [/etc/kubernetes/pki/apiserver.crt] total size is: 1.33KB ;speed is 1KB
06:54:04 [DEBG] [scp.go:337] [ssh][172.24.20.52:22]transfer local [/root/.sealos/pki/apiserver.crt] to Dst [/etc/kubernetes/pki/apiserver.crt] total size is: 1.33KB ;speed is 1KB
06:54:05 [DEBG] [scp.go:337] [ssh][172.24.20.53:22]transfer local [/root/.sealos/pki/apiserver.key] to Dst [/etc/kubernetes/pki/apiserver.key] total size is: 1.64KB ;speed is 1KB
06:54:05 [DEBG] [scp.go:337] [ssh][172.24.20.52:22]transfer local [/root/.sealos/pki/apiserver.key] to Dst [/etc/kubernetes/pki/apiserver.key] total size is: 1.64KB ;speed is 1KB
06:54:05 [DEBG] [scp.go:337] [ssh][172.24.20.53:22]transfer local [/root/.sealos/pki/ca.crt] to Dst [/etc/kubernetes/pki/ca.crt] total size is: 1.04KB ;speed is 1KB
06:54:05 [DEBG] [scp.go:337] [ssh][172.24.20.52:22]transfer local [/root/.sealos/pki/ca.crt] to Dst [/etc/kubernetes/pki/ca.crt] total size is: 1.04KB ;speed is 1KB
06:54:06 [DEBG] [scp.go:337] [ssh][172.24.20.53:22]transfer local [/root/.sealos/pki/ca.key] to Dst [/etc/kubernetes/pki/ca.key] total size is: 1.64KB ;speed is 1KB
06:54:06 [DEBG] [scp.go:337] [ssh][172.24.20.52:22]transfer local [/root/.sealos/pki/ca.key] to Dst [/etc/kubernetes/pki/ca.key] total size is: 1.64KB ;speed is 1KB
06:54:06 [DEBG] [scp.go:337] [ssh][172.24.20.53:22]transfer local [/root/.sealos/pki/etcd/ca.crt] to Dst [/etc/kubernetes/pki/etcd/ca.crt] total size is: 1.04KB ;speed is 1KB
06:54:06 [DEBG] [scp.go:337] [ssh][172.24.20.52:22]transfer local [/root/.sealos/pki/etcd/ca.crt] to Dst [/etc/kubernetes/pki/etcd/ca.crt] total size is: 1.04KB ;speed is 1KB
06:54:07 [DEBG] [scp.go:337] [ssh][172.24.20.53:22]transfer local [/root/.sealos/pki/etcd/ca.key] to Dst [/etc/kubernetes/pki/etcd/ca.key] total size is: 1.64KB ;speed is 1KB
06:54:07 [DEBG] [scp.go:337] [ssh][172.24.20.52:22]transfer local [/root/.sealos/pki/etcd/ca.key] to Dst [/etc/kubernetes/pki/etcd/ca.key] total size is: 1.64KB ;speed is 1KB
06:54:07 [DEBG] [scp.go:337] [ssh][172.24.20.53:22]transfer local [/root/.sealos/pki/etcd/healthcheck-client.crt] to Dst [/etc/kubernetes/pki/etcd/healthcheck-client.crt] total size is: 1.12KB ;speed is 1KB
06:54:07 [DEBG] [scp.go:337] [ssh][172.24.20.52:22]transfer local [/root/.sealos/pki/etcd/healthcheck-client.crt] to Dst [/etc/kubernetes/pki/etcd/healthcheck-client.crt] total size is: 1.12KB ;speed is 1KB
06:54:08 [DEBG] [scp.go:337] [ssh][172.24.20.53:22]transfer local [/root/.sealos/pki/etcd/healthcheck-client.key] to Dst [/etc/kubernetes/pki/etcd/healthcheck-client.key] total size is: 1.64KB ;speed is 1KB
06:54:08 [DEBG] [scp.go:337] [ssh][172.24.20.52:22]transfer local [/root/.sealos/pki/etcd/healthcheck-client.key] to Dst [/etc/kubernetes/pki/etcd/healthcheck-client.key] total size is: 1.64KB ;speed is 1KB
06:54:08 [DEBG] [scp.go:337] [ssh][172.24.20.53:22]transfer local [/root/.sealos/pki/etcd/peer.crt] to Dst [/etc/kubernetes/pki/etcd/peer.crt] total size is: 1.16KB ;speed is 1KB
06:54:08 [DEBG] [scp.go:337] [ssh][172.24.20.52:22]transfer local [/root/.sealos/pki/etcd/peer.crt] to Dst [/etc/kubernetes/pki/etcd/peer.crt] total size is: 1.16KB ;speed is 1KB
06:54:09 [DEBG] [scp.go:337] [ssh][172.24.20.53:22]transfer local [/root/.sealos/pki/etcd/peer.key] to Dst [/etc/kubernetes/pki/etcd/peer.key] total size is: 1.64KB ;speed is 1KB
06:54:09 [DEBG] [scp.go:337] [ssh][172.24.20.52:22]transfer local [/root/.sealos/pki/etcd/peer.key] to Dst [/etc/kubernetes/pki/etcd/peer.key] total size is: 1.64KB ;speed is 1KB
06:54:09 [DEBG] [scp.go:337] [ssh][172.24.20.53:22]transfer local [/root/.sealos/pki/etcd/server.crt] to Dst [/etc/kubernetes/pki/etcd/server.crt] total size is: 1.16KB ;speed is 1KB
06:54:10 [DEBG] [scp.go:337] [ssh][172.24.20.52:22]transfer local [/root/.sealos/pki/etcd/server.crt] to Dst [/etc/kubernetes/pki/etcd/server.crt] total size is: 1.16KB ;speed is 1KB
06:54:10 [DEBG] [scp.go:337] [ssh][172.24.20.53:22]transfer local [/root/.sealos/pki/etcd/server.key] to Dst [/etc/kubernetes/pki/etcd/server.key] total size is: 1.64KB ;speed is 1KB
06:54:10 [DEBG] [scp.go:337] [ssh][172.24.20.52:22]transfer local [/root/.sealos/pki/etcd/server.key] to Dst [/etc/kubernetes/pki/etcd/server.key] total size is: 1.64KB ;speed is 1KB
06:54:11 [DEBG] [scp.go:337] [ssh][172.24.20.53:22]transfer local [/root/.sealos/pki/front-proxy-ca.crt] to Dst [/etc/kubernetes/pki/front-proxy-ca.crt] total size is: 1.06KB ;speed is 1KB
06:54:11 [DEBG] [scp.go:337] [ssh][172.24.20.52:22]transfer local [/root/.sealos/pki/front-proxy-ca.crt] to Dst [/etc/kubernetes/pki/front-proxy-ca.crt] total size is: 1.06KB ;speed is 1KB
06:54:11 [DEBG] [scp.go:337] [ssh][172.24.20.53:22]transfer local [/root/.sealos/pki/front-proxy-ca.key] to Dst [/etc/kubernetes/pki/front-proxy-ca.key] total size is: 1.64KB ;speed is 1KB
06:54:12 [DEBG] [scp.go:337] [ssh][172.24.20.52:22]transfer local [/root/.sealos/pki/front-proxy-ca.key] to Dst [/etc/kubernetes/pki/front-proxy-ca.key] total size is: 1.64KB ;speed is 1KB
06:54:12 [DEBG] [scp.go:337] [ssh][172.24.20.53:22]transfer local [/root/.sealos/pki/front-proxy-client.crt] to Dst [/etc/kubernetes/pki/front-proxy-client.crt] total size is: 1.08KB ;speed is 1KB
06:54:12 [DEBG] [scp.go:337] [ssh][172.24.20.52:22]transfer local [/root/.sealos/pki/front-proxy-client.crt] to Dst [/etc/kubernetes/pki/front-proxy-client.crt] total size is: 1.08KB ;speed is 1KB
06:54:12 [DEBG] [scp.go:337] [ssh][172.24.20.53:22]transfer local [/root/.sealos/pki/front-proxy-client.key] to Dst [/etc/kubernetes/pki/front-proxy-client.key] total size is: 1.64KB ;speed is 1KB
06:54:13 [DEBG] [scp.go:337] [ssh][172.24.20.52:22]transfer local [/root/.sealos/pki/front-proxy-client.key] to Dst [/etc/kubernetes/pki/front-proxy-client.key] total size is: 1.64KB ;speed is 1KB
06:54:13 [DEBG] [scp.go:337] [ssh][172.24.20.53:22]transfer local [/root/.sealos/pki/sa.key] to Dst [/etc/kubernetes/pki/sa.key] total size is: 1.64KB ;speed is 1KB
06:54:13 [DEBG] [scp.go:337] [ssh][172.24.20.52:22]transfer local [/root/.sealos/pki/sa.key] to Dst [/etc/kubernetes/pki/sa.key] total size is: 1.64KB ;speed is 1KB
06:54:14 [DEBG] [scp.go:337] [ssh][172.24.20.53:22]transfer local [/root/.sealos/pki/sa.pub] to Dst [/etc/kubernetes/pki/sa.pub] total size is: 0.44KB ;speed is 0KB
06:54:14 [DEBG] [scp.go:337] [ssh][172.24.20.52:22]transfer local [/root/.sealos/pki/sa.pub] to Dst [/etc/kubernetes/pki/sa.pub] total size is: 0.44KB ;speed is 0KB
06:54:14 [DEBG] [ssh.go:58] [172.24.20.52:22] echo &#34;apiVersion: kubeadm.k8s.io/v1beta2
caCertPath: /etc/kubernetes/pki/ca.crt
discovery:
  bootstrapToken:
    apiServerEndpoint: 172.24.20.51:6443
    token: 7tfbyw.qgkimu2s8z4wq3fh
    caCertHashes:
    - sha256:495a8e10ba234a29e827960e1b985e326bd27471631396b6c4b26084796b8567
  timeout: 5m0s
kind: JoinConfiguration
controlPlane:
  localAPIEndpoint:
    advertiseAddress: 172.24.20.52
    bindPort: 6443
nodeRegistration:
  criSocket: /var/run/dockershim.sock&#34; &gt; /root/kubeadm-join-config.yaml
06:54:14 [DEBG] [ssh.go:58] [172.24.20.53:22] echo &#34;apiVersion: kubeadm.k8s.io/v1beta2
caCertPath: /etc/kubernetes/pki/ca.crt
discovery:
  bootstrapToken:
    apiServerEndpoint: 172.24.20.51:6443
    token: 7tfbyw.qgkimu2s8z4wq3fh
    caCertHashes:
    - sha256:495a8e10ba234a29e827960e1b985e326bd27471631396b6c4b26084796b8567
  timeout: 5m0s
kind: JoinConfiguration
controlPlane:
  localAPIEndpoint:
    advertiseAddress: 172.24.20.53
    bindPort: 6443
nodeRegistration:
  criSocket: /var/run/dockershim.sock&#34; &gt; /root/kubeadm-join-config.yaml
06:54:15 [INFO] [ssh.go:13] [ssh][172.24.20.53:22] hostname
06:54:15 [INFO] [ssh.go:13] [ssh][172.24.20.52:22] hostname
06:54:16 [DEBG] [ssh.go:25] [ssh][172.24.20.52:22]command result is: cloudos-52

06:54:16 [DEBG] [ssh.go:58] [172.24.20.52:22] sealos cert  --node-ip 172.24.20.52 --node-name cloudos-52 --service-cidr 10.40.0.0/16 --dns-domain cluster.local --alt-names 127.0.0.1 --alt-names apiserver.cluster.local --alt-names 172.24.20.51 --alt-names 172.24.20.52 --alt-names 172.24.20.53 --alt-names 10.10.10.10
06:54:16 [DEBG] [ssh.go:25] [ssh][172.24.20.53:22]command result is: cloudos-53

06:54:16 [DEBG] [ssh.go:58] [172.24.20.53:22] sealos cert  --node-ip 172.24.20.53 --node-name cloudos-53 --service-cidr 10.40.0.0/16 --dns-domain cluster.local --alt-names 127.0.0.1 --alt-names apiserver.cluster.local --alt-names 172.24.20.51 --alt-names 172.24.20.52 --alt-names 172.24.20.53 --alt-names 10.10.10.10
06:54:16 [INFO] [ssh.go:51] [172.24.20.53:22] 06:54:19 [INFO] [kube_certs.go:223] apiserver altNames : {map[apiserver.cluster.local:apiserver.cluster.local cloudos-53:cloudos-53 kubernetes:kubernetes kubernetes.default:kubernetes.default kubernetes.default.svc:kubernetes.default.svc kubernetes.default.svc.cluster.local:kubernetes.default.svc.cluster.local localhost:localhost] map[10.10.10.10:10.10.10.10 10.40.0.1:10.40.0.1 127.0.0.1:127.0.0.1 172.24.20.51:172.24.20.51 172.24.20.52:172.24.20.52 172.24.20.53:172.24.20.53]}
06:54:16 [INFO] [ssh.go:51] [172.24.20.53:22] 06:54:19 [INFO] [kube_certs.go:243] Etcd altnames : {map[cloudos-53:cloudos-53 localhost:localhost] map[127.0.0.1:127.0.0.1 172.24.20.53:172.24.20.53 ::1:::1]}, commonName : cloudos-53
06:54:16 [INFO] [ssh.go:51] [172.24.20.53:22] 06:54:19 [INFO] [kube_certs.go:251] sa.key sa.pub already exist
06:54:16 [INFO] [ssh.go:51] [172.24.20.52:22] 06:54:19 [INFO] [kube_certs.go:223] apiserver altNames : {map[apiserver.cluster.local:apiserver.cluster.local cloudos-52:cloudos-52 kubernetes:kubernetes kubernetes.default:kubernetes.default kubernetes.default.svc:kubernetes.default.svc kubernetes.default.svc.cluster.local:kubernetes.default.svc.cluster.local localhost:localhost] map[10.10.10.10:10.10.10.10 10.40.0.1:10.40.0.1 127.0.0.1:127.0.0.1 172.24.20.51:172.24.20.51 172.24.20.52:172.24.20.52 172.24.20.53:172.24.20.53]}
06:54:16 [INFO] [ssh.go:51] [172.24.20.52:22] 06:54:19 [INFO] [kube_certs.go:243] Etcd altnames : {map[cloudos-52:cloudos-52 localhost:localhost] map[127.0.0.1:127.0.0.1 172.24.20.52:172.24.20.52 ::1:::1]}, commonName : cloudos-52
06:54:16 [INFO] [ssh.go:51] [172.24.20.52:22] 06:54:19 [INFO] [kube_certs.go:251] sa.key sa.pub already exist
06:54:19 [DEBG] [ssh.go:58] [172.24.20.53:22] echo 172.24.20.51 apiserver.cluster.local &gt;&gt; /etc/hosts
06:54:19 [DEBG] [ssh.go:58] [172.24.20.53:22] kubeadm join --config=/root/kubeadm-join-config.yaml  -v 0
06:54:19 [DEBG] [ssh.go:58] [172.24.20.52:22] echo 172.24.20.51 apiserver.cluster.local &gt;&gt; /etc/hosts
06:54:20 [INFO] [ssh.go:51] [172.24.20.53:22] [preflight] Running pre-flight checks
06:54:20 [DEBG] [ssh.go:58] [172.24.20.52:22] kubeadm join --config=/root/kubeadm-join-config.yaml  -v 0
06:54:20 [INFO] [ssh.go:51] [172.24.20.53:22]   [WARNING IsDockerSystemdCheck]: detected &#34;cgroupfs&#34; as the Docker cgroup driver. The recommended driver is &#34;systemd&#34;. Please follow the guide at https://kubernetes.io/docs/setup/cri/
06:54:20 [INFO] [ssh.go:51] [172.24.20.53:22]   [WARNING FileExisting-socat]: socat not found in system path
06:54:20 [INFO] [ssh.go:51] [172.24.20.53:22]   [WARNING FileExisting-tc]: tc not found in system path
06:54:21 [INFO] [ssh.go:51] [172.24.20.53:22] [preflight] Reading configuration from the cluster...
06:54:21 [INFO] [ssh.go:51] [172.24.20.53:22] [preflight] FYI: You can look at this config file with &#39;kubectl -n kube-system get cm kubeadm-config -oyaml&#39;
06:54:21 [INFO] [ssh.go:51] [172.24.20.52:22] [preflight] Running pre-flight checks
06:54:21 [INFO] [ssh.go:51] [172.24.20.53:22] [preflight] Running pre-flight checks before initializing the new control plane instance
06:54:21 [INFO] [ssh.go:51] [172.24.20.53:22] [preflight] Pulling images required for setting up a Kubernetes cluster
06:54:21 [INFO] [ssh.go:51] [172.24.20.53:22] [preflight] This might take a minute or two, depending on the speed of your internet connection
06:54:21 [INFO] [ssh.go:51] [172.24.20.53:22] [preflight] You can also perform this action in beforehand using &#39;kubeadm config images pull&#39;
06:54:21 [INFO] [ssh.go:51] [172.24.20.53:22] [certs] Using certificateDir folder &#34;/etc/kubernetes/pki&#34;
06:54:22 [INFO] [ssh.go:51] [172.24.20.52:22]   [WARNING IsDockerSystemdCheck]: detected &#34;cgroupfs&#34; as the Docker cgroup driver. The recommended driver is &#34;systemd&#34;. Please follow the guide at https://kubernetes.io/docs/setup/cri/
06:54:22 [INFO] [ssh.go:51] [172.24.20.52:22]   [WARNING FileExisting-socat]: socat not found in system path
06:54:22 [INFO] [ssh.go:51] [172.24.20.52:22]   [WARNING FileExisting-tc]: tc not found in system path
06:54:22 [INFO] [ssh.go:51] [172.24.20.53:22] [certs] Using the existing &#34;front-proxy-client&#34; certificate and key
06:54:22 [INFO] [ssh.go:51] [172.24.20.53:22] [certs] Using the existing &#34;etcd/server&#34; certificate and key
06:54:22 [INFO] [ssh.go:51] [172.24.20.52:22] [preflight] Reading configuration from the cluster...
06:54:22 [INFO] [ssh.go:51] [172.24.20.52:22] [preflight] FYI: You can look at this config file with &#39;kubectl -n kube-system get cm kubeadm-config -oyaml&#39;
06:54:23 [INFO] [ssh.go:51] [172.24.20.52:22] [preflight] Running pre-flight checks before initializing the new control plane instance
06:54:23 [INFO] [ssh.go:51] [172.24.20.52:22] [preflight] Pulling images required for setting up a Kubernetes cluster
06:54:23 [INFO] [ssh.go:51] [172.24.20.52:22] [preflight] This might take a minute or two, depending on the speed of your internet connection
06:54:23 [INFO] [ssh.go:51] [172.24.20.52:22] [preflight] You can also perform this action in beforehand using &#39;kubeadm config images pull&#39;
06:54:23 [INFO] [ssh.go:51] [172.24.20.53:22] [certs] Using the existing &#34;etcd/peer&#34; certificate and key
06:54:23 [INFO] [ssh.go:51] [172.24.20.52:22] [certs] Using certificateDir folder &#34;/etc/kubernetes/pki&#34;
06:54:23 [INFO] [ssh.go:51] [172.24.20.53:22] [certs] Using the existing &#34;etcd/healthcheck-client&#34; certificate and key
06:54:23 [INFO] [ssh.go:51] [172.24.20.52:22] [certs] Using the existing &#34;etcd/healthcheck-client&#34; certificate and key
06:54:23 [INFO] [ssh.go:51] [172.24.20.53:22] [certs] Using the existing &#34;apiserver-etcd-client&#34; certificate and key
06:54:24 [INFO] [ssh.go:51] [172.24.20.53:22] [certs] Using the existing &#34;apiserver-kubelet-client&#34; certificate and key
06:54:24 [INFO] [ssh.go:51] [172.24.20.53:22] [certs] Using the existing &#34;apiserver&#34; certificate and key
06:54:24 [INFO] [ssh.go:51] [172.24.20.53:22] [certs] Valid certificates and keys now exist in &#34;/etc/kubernetes/pki&#34;
06:54:24 [INFO] [ssh.go:51] [172.24.20.53:22] [certs] Using the existing &#34;sa&#34; key
06:54:24 [INFO] [ssh.go:51] [172.24.20.53:22] [kubeconfig] Generating kubeconfig files
06:54:24 [INFO] [ssh.go:51] [172.24.20.53:22] [kubeconfig] Using kubeconfig folder &#34;/etc/kubernetes&#34;
06:54:24 [INFO] [ssh.go:51] [172.24.20.53:22] [kubeconfig] Using existing kubeconfig file: &#34;/etc/kubernetes/admin.conf&#34;
06:54:24 [INFO] [ssh.go:51] [172.24.20.52:22] [certs] Using the existing &#34;apiserver-etcd-client&#34; certificate and key
06:54:24 [INFO] [ssh.go:51] [172.24.20.53:22] [kubeconfig] Using existing kubeconfig file: &#34;/etc/kubernetes/controller-manager.conf&#34;
06:54:24 [INFO] [ssh.go:51] [172.24.20.52:22] [certs] Using the existing &#34;etcd/peer&#34; certificate and key
06:54:25 [INFO] [ssh.go:51] [172.24.20.52:22] [certs] Using the existing &#34;etcd/server&#34; certificate and key
06:54:25 [INFO] [ssh.go:51] [172.24.20.52:22] [certs] Using the existing &#34;apiserver&#34; certificate and key
06:54:25 [INFO] [ssh.go:51] [172.24.20.53:22] [kubeconfig] Using existing kubeconfig file: &#34;/etc/kubernetes/scheduler.conf&#34;
06:54:25 [INFO] [ssh.go:51] [172.24.20.53:22] [control-plane] Using manifest folder &#34;/etc/kubernetes/manifests&#34;
06:54:25 [INFO] [ssh.go:51] [172.24.20.53:22] [control-plane] Creating static Pod manifest for &#34;kube-apiserver&#34;
06:54:25 [INFO] [ssh.go:51] [172.24.20.53:22] [control-plane] Creating static Pod manifest for &#34;kube-controller-manager&#34;
06:54:25 [INFO] [ssh.go:51] [172.24.20.53:22] [control-plane] Creating static Pod manifest for &#34;kube-scheduler&#34;
06:54:25 [INFO] [ssh.go:51] [172.24.20.53:22] [check-etcd] Checking that the etcd cluster is healthy
06:54:25 [INFO] [ssh.go:51] [172.24.20.53:22] [kubelet-start] Writing kubelet configuration to file &#34;/var/lib/kubelet/config.yaml&#34;
06:54:25 [INFO] [ssh.go:51] [172.24.20.53:22] [kubelet-start] Writing kubelet environment file with flags to file &#34;/var/lib/kubelet/kubeadm-flags.env&#34;
06:54:25 [INFO] [ssh.go:51] [172.24.20.53:22] [kubelet-start] Starting the kubelet
06:54:25 [INFO] [ssh.go:51] [172.24.20.52:22] [certs] Using the existing &#34;apiserver-kubelet-client&#34; certificate and key
06:54:25 [INFO] [ssh.go:51] [172.24.20.52:22] [certs] Using the existing &#34;front-proxy-client&#34; certificate and key
06:54:25 [INFO] [ssh.go:51] [172.24.20.52:22] [certs] Valid certificates and keys now exist in &#34;/etc/kubernetes/pki&#34;
06:54:25 [INFO] [ssh.go:51] [172.24.20.52:22] [certs] Using the existing &#34;sa&#34; key
06:54:25 [INFO] [ssh.go:51] [172.24.20.52:22] [kubeconfig] Generating kubeconfig files
06:54:25 [INFO] [ssh.go:51] [172.24.20.52:22] [kubeconfig] Using kubeconfig folder &#34;/etc/kubernetes&#34;
06:54:26 [INFO] [ssh.go:51] [172.24.20.53:22] [kubelet-start] Waiting for the kubelet to perform the TLS Bootstrap...
06:54:26 [INFO] [ssh.go:51] [172.24.20.52:22] [kubeconfig] Using existing kubeconfig file: &#34;/etc/kubernetes/admin.conf&#34;
06:54:26 [INFO] [ssh.go:51] [172.24.20.52:22] [kubeconfig] Using existing kubeconfig file: &#34;/etc/kubernetes/controller-manager.conf&#34;
06:54:26 [INFO] [ssh.go:51] [172.24.20.52:22] [kubeconfig] Using existing kubeconfig file: &#34;/etc/kubernetes/scheduler.conf&#34;
06:54:26 [INFO] [ssh.go:51] [172.24.20.52:22] [control-plane] Using manifest folder &#34;/etc/kubernetes/manifests&#34;
06:54:26 [INFO] [ssh.go:51] [172.24.20.52:22] [control-plane] Creating static Pod manifest for &#34;kube-apiserver&#34;
06:54:26 [INFO] [ssh.go:51] [172.24.20.52:22] [control-plane] Creating static Pod manifest for &#34;kube-controller-manager&#34;
06:54:26 [INFO] [ssh.go:51] [172.24.20.52:22] [control-plane] Creating static Pod manifest for &#34;kube-scheduler&#34;
06:54:26 [INFO] [ssh.go:51] [172.24.20.52:22] [check-etcd] Checking that the etcd cluster is healthy
06:54:26 [INFO] [ssh.go:51] [172.24.20.52:22] [kubelet-start] Writing kubelet configuration to file &#34;/var/lib/kubelet/config.yaml&#34;
06:54:26 [INFO] [ssh.go:51] [172.24.20.52:22] [kubelet-start] Writing kubelet environment file with flags to file &#34;/var/lib/kubelet/kubeadm-flags.env&#34;
06:54:26 [INFO] [ssh.go:51] [172.24.20.52:22] [kubelet-start] Starting the kubelet
06:54:28 [INFO] [ssh.go:51] [172.24.20.52:22] [kubelet-start] Waiting for the kubelet to perform the TLS Bootstrap...
06:54:34 [INFO] [ssh.go:51] [172.24.20.53:22] [etcd] Announced new etcd member joining to the existing etcd cluster
06:54:34 [INFO] [ssh.go:51] [172.24.20.53:22] [etcd] Creating static Pod manifest for &#34;etcd&#34;
06:54:34 [INFO] [ssh.go:51] [172.24.20.53:22] [etcd] Waiting for the new etcd member to join the cluster. This can take up to 40s
06:54:45 [INFO] [ssh.go:51] [172.24.20.53:22] [upload-config] Storing the configuration used in ConfigMap &#34;kubeadm-config&#34; in the &#34;kube-system&#34; Namespace
06:54:52 [INFO] [ssh.go:51] [172.24.20.52:22] [etcd] Announced new etcd member joining to the existing etcd cluster
06:54:52 [INFO] [ssh.go:51] [172.24.20.52:22] [etcd] Creating static Pod manifest for &#34;etcd&#34;
06:54:52 [INFO] [ssh.go:51] [172.24.20.52:22] [etcd] Waiting for the new etcd member to join the cluster. This can take up to 40s
06:54:53 [INFO] [ssh.go:51] [172.24.20.53:22] [mark-control-plane] Marking the node cloudos-53 as control-plane by adding the label &#34;node-role.kubernetes.io/master=&#39;&#39;&#34;
06:54:53 [INFO] [ssh.go:51] [172.24.20.53:22] [mark-control-plane] Marking the node cloudos-53 as control-plane by adding the taints [node-role.kubernetes.io/master:NoSchedule]
06:54:54 [INFO] [ssh.go:51] [172.24.20.53:22] 
06:54:54 [INFO] [ssh.go:51] [172.24.20.53:22] This node has joined the cluster and a new control plane instance was created:
06:54:54 [INFO] [ssh.go:51] [172.24.20.53:22] 
06:54:54 [INFO] [ssh.go:51] [172.24.20.53:22] * Certificate signing request was sent to apiserver and approval was received.
06:54:54 [INFO] [ssh.go:51] [172.24.20.53:22] * The Kubelet was informed of the new secure connection details.
06:54:54 [INFO] [ssh.go:51] [172.24.20.53:22] * Control plane (master) label and taint were applied to the new node.
06:54:54 [INFO] [ssh.go:51] [172.24.20.53:22] * The Kubernetes control plane instances scaled up.
06:54:54 [INFO] [ssh.go:51] [172.24.20.53:22] * A new etcd member was added to the local/stacked etcd cluster.
06:54:54 [INFO] [ssh.go:51] [172.24.20.53:22] 
06:54:54 [INFO] [ssh.go:51] [172.24.20.53:22] To start administering your cluster from this node, you need to run the following as a regular user:
06:54:54 [INFO] [ssh.go:51] [172.24.20.53:22] 
06:54:54 [INFO] [ssh.go:51] [172.24.20.53:22]   mkdir -p $HOME/.kube
06:54:54 [INFO] [ssh.go:51] [172.24.20.53:22]   sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config
06:54:54 [INFO] [ssh.go:51] [172.24.20.53:22]   sudo chown $(id -u):$(id -g) $HOME/.kube/config
06:54:54 [INFO] [ssh.go:51] [172.24.20.53:22] 
06:54:54 [INFO] [ssh.go:51] [172.24.20.53:22] Run &#39;kubectl get nodes&#39; to see this node join the cluster.
06:54:54 [INFO] [ssh.go:51] [172.24.20.53:22] 
06:54:54 [DEBG] [ssh.go:58] [172.24.20.53:22] sed &#34;s/172.24.20.51 apiserver.cluster.local/172.24.20.53 apiserver.cluster.local/g&#34; -i /etc/hosts
06:54:55 [INFO] [ssh.go:51] [172.24.20.52:22] [upload-config] Storing the configuration used in ConfigMap &#34;kubeadm-config&#34; in the &#34;kube-system&#34; Namespace
06:54:55 [INFO] [ssh.go:51] [172.24.20.52:22] [mark-control-plane] Marking the node cloudos-52 as control-plane by adding the label &#34;node-role.kubernetes.io/master=&#39;&#39;&#34;
06:54:55 [INFO] [ssh.go:51] [172.24.20.52:22] [mark-control-plane] Marking the node cloudos-52 as control-plane by adding the taints [node-role.kubernetes.io/master:NoSchedule]
06:54:56 [INFO] [ssh.go:51] [172.24.20.52:22] 
06:54:56 [INFO] [ssh.go:51] [172.24.20.52:22] This node has joined the cluster and a new control plane instance was created:
06:54:56 [INFO] [ssh.go:51] [172.24.20.52:22] 
06:54:56 [INFO] [ssh.go:51] [172.24.20.52:22] * Certificate signing request was sent to apiserver and approval was received.
06:54:56 [INFO] [ssh.go:51] [172.24.20.52:22] * The Kubelet was informed of the new secure connection details.
06:54:56 [INFO] [ssh.go:51] [172.24.20.52:22] * Control plane (master) label and taint were applied to the new node.
06:54:56 [INFO] [ssh.go:51] [172.24.20.52:22] * The Kubernetes control plane instances scaled up.
06:54:56 [INFO] [ssh.go:51] [172.24.20.52:22] * A new etcd member was added to the local/stacked etcd cluster.
06:54:56 [INFO] [ssh.go:51] [172.24.20.52:22] 
06:54:56 [INFO] [ssh.go:51] [172.24.20.52:22] To start administering your cluster from this node, you need to run the following as a regular user:
06:54:56 [INFO] [ssh.go:51] [172.24.20.52:22] 
06:54:56 [INFO] [ssh.go:51] [172.24.20.52:22]   mkdir -p $HOME/.kube
06:54:56 [INFO] [ssh.go:51] [172.24.20.52:22]   sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config
06:54:56 [INFO] [ssh.go:51] [172.24.20.52:22]   sudo chown $(id -u):$(id -g) $HOME/.kube/config
06:54:56 [INFO] [ssh.go:51] [172.24.20.52:22] 
06:54:56 [INFO] [ssh.go:51] [172.24.20.52:22] Run &#39;kubectl get nodes&#39; to see this node join the cluster.
06:54:56 [INFO] [ssh.go:51] [172.24.20.52:22] 
06:54:56 [DEBG] [ssh.go:58] [172.24.20.52:22] sed &#34;s/172.24.20.51 apiserver.cluster.local/172.24.20.52 apiserver.cluster.local/g&#34; -i /etc/hosts
06:54:56 [DEBG] [ssh.go:58] [172.24.20.53:22] rm -rf .kube/config &amp;&amp; mkdir -p /root/.kube &amp;&amp; cp /etc/kubernetes/admin.conf /root/.kube/config &amp;&amp; chmod 600 /root/.kube/config
06:54:57 [DEBG] [ssh.go:58] [172.24.20.52:22] rm -rf .kube/config &amp;&amp; mkdir -p /root/.kube &amp;&amp; cp /etc/kubernetes/admin.conf /root/.kube/config &amp;&amp; chmod 600 /root/.kube/config
06:54:58 [DEBG] [ssh.go:58] [172.24.20.53:22] rm -rf /root/kube || :
06:54:58 [DEBG] [ssh.go:58] [172.24.20.52:22] rm -rf /root/kube || :
06:55:02 [DEBG] [print.go:21] ==&gt;SendPackage==&gt;KubeadmConfigInstall==&gt;InstallMaster0==&gt;JoinMasters
06:55:02 [INFO] [print.go:26] sealos install success.
06:55:02 [INFO] [init.go:95] 
</code></pre><h2 id=3验证>3.验证</h2><pre tabindex=0><code>[root@cloudos-51 ~]# kubectl get node -o wide
NAME         STATUS   ROLES    AGE     VERSION   INTERNAL-IP    EXTERNAL-IP   OS-IMAGE          KERNEL-VERSION       CONTAINER-RUNTIME
cloudos-51   Ready    master   7m32s   v1.19.0   172.24.20.51   &lt;none&gt;        OpenCloudOS 8.6   5.4.119-20.0009.20   docker://19.3.0
cloudos-52   Ready    master   6m42s   v1.19.0   172.24.20.52   &lt;none&gt;        OpenCloudOS 8.6   5.4.119-20.0009.20   docker://19.3.0
cloudos-53   Ready    master   6m43s   v1.19.0   172.24.20.53   &lt;none&gt;        OpenCloudOS 8.6   5.4.119-20.0009.20   docker://19.3.0
[root@cloudos-51 ~]# 
[root@cloudos-51 ~]# kubectl get cs
Warning: v1 ComponentStatus is deprecated in v1.19+
NAME                 STATUS      MESSAGE                                                                                       ERROR
controller-manager   Unhealthy   Get &#34;http://127.0.0.1:10252/healthz&#34;: dial tcp 127.0.0.1:10252: connect: connection refused   
scheduler            Unhealthy   Get &#34;http://127.0.0.1:10251/healthz&#34;: dial tcp 127.0.0.1:10251: connect: connection refused   
etcd-0               Healthy     {&#34;health&#34;:&#34;true&#34;}   

//解决cs组件状态异常
/etc/kubernetes/manifests/    //注释  #- --port=0
kube-controller-manager.yaml
kube-scheduler.yaml

[root@cloudos-51 manifests]# kubectl get cs
Warning: v1 ComponentStatus is deprecated in v1.19+
NAME                 STATUS    MESSAGE             ERROR
controller-manager   Healthy   ok                  
scheduler            Healthy   ok                  
etcd-0               Healthy   {&#34;health&#34;:&#34;true&#34;}
</code></pre><pre tabindex=0><code>//取消污点
kubectl taint node cloudos-51  node-role.kubernetes.io/master-

//Start a busybox pod and keep it in the foreground, don&#39;t restart it if it exits.kubectl run -i -t busybox --image=busybox --restart=Never

kubectl run -i -t busybox --image=busybox  -- sh

[root@cloudos-51 ~]# kubectl exec -it busybox -- sh
/ # ip a
1: lo: &lt;LOOPBACK,UP,LOWER_UP&gt; mtu 65536 qdisc noqueue qlen 1000
    link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00
    inet 127.0.0.1/8 scope host lo
       valid_lft forever preferred_lft forever
2: tunl0@NONE: &lt;NOARP&gt; mtu 1480 qdisc noop qlen 1000
    link/ipip 0.0.0.0 brd 0.0.0.0
4: eth0@if9: &lt;BROADCAST,MULTICAST,UP,LOWER_UP,M-DOWN&gt; mtu 1440 qdisc noqueue 
    link/ether 02:4c:0b:4a:4a:c7 brd ff:ff:ff:ff:ff:ff
    inet 10.20.174.194/32 scope global eth0
       valid_lft forever preferred_lft forever
/ # ping 10.40.0.1
PING 10.40.0.1 (10.40.0.1): 56 data bytes
64 bytes from 10.40.0.1: seq=0 ttl=64 time=2.869 ms
64 bytes from 10.40.0.1: seq=1 ttl=64 time=0.191 ms
64 bytes from 10.40.0.1: seq=2 ttl=64 time=0.109 ms
^C
--- 10.40.0.1 ping statistics ---
3 packets transmitted, 3 packets received, 0% packet loss
round-trip min/avg/max = 0.109/1.056/2.869 ms
/ # ping 172.24.20.51
PING 172.24.20.51 (172.24.20.51): 56 data bytes
64 bytes from 172.24.20.51: seq=0 ttl=63 time=2.362 ms
^C
--- 172.24.20.51 ping statistics ---
1 packets transmitted, 1 packets received, 0% packet loss
round-trip min/avg/max = 2.362/2.362/2.362 ms
/ # ping 172.24.20.53
PING 172.24.20.53 (172.24.20.53): 56 data bytes
64 bytes from 172.24.20.53: seq=0 ttl=64 time=0.155 ms
64 bytes from 172.24.20.53: seq=1 ttl=64 time=0.198 ms
^C
--- 172.24.20.53 ping statistics ---
2 packets transmitted, 2 packets received, 0% packet loss
round-trip min/avg/max = 0.155/0.176/0.198 ms
/ # ping 172.20.20.53
PING 172.20.20.53 (172.20.20.53): 56 data bytes
64 bytes from 172.20.20.53: seq=0 ttl=64 time=0.140 ms
64 bytes from 172.20.20.53: seq=1 ttl=64 time=0.113 ms
^C
--- 172.20.20.53 ping statistics ---
2 packets transmitted, 2 packets received, 0% packet loss
round-trip min/avg/max = 0.113/0.126/0.140 ms
</code></pre><h2 id=4集群节点操作>4.集群节点操作</h2><pre tabindex=0><code># 增加master
sealos join --master 192.168.0.6 --master 192.168.0.7
sealos join --master 192.168.0.6-192.168.0.9  # 或者多个连续IP

# 增加node 
sealos join --node 192.168.0.6 --node 192.168.0.7
sealos join --node 192.168.0.6-192.168.0.9  # 或者多个连续IP

# 删除指定master节点 
sealos clean --master 192.168.0.6 --master 192.168.0.7
sealos clean --master 192.168.0.6-192.168.0.9  # 或者多个连续IP

# 删除指定node节点 
sealos clean --node 192.168.0.6 --node 192.168.0.7
sealos clean --node 192.168.0.6-192.168.0.9  # 或者多个连续IP

# 清理集群
sealos clean --all 
</code></pre></div><div class=post-archive><h2>相关文章</h2><ul class=listing><li><a href=/2022/09/2sealos-v3%E5%8D%95%E8%8A%82%E7%82%B9%E9%83%A8%E7%BD%B2/>(2)sealos-v3单节点部署</a></li><li><a href=/2022/09/1sealos-v3%E7%AE%80%E4%BB%8B/>(1)sealos-v3简介</a></li><li><a href=/2022/08/nginx%E5%9F%BA%E4%BA%8Ejemalloc-lua%E6%9E%84%E5%BB%BA/>nginx基于jemalloc-lua构建</a></li><li><a href=/2022/03/mysql-8.0.x%E6%90%AD%E5%BB%BA%E4%B8%BB%E4%BB%8E/>mysql-8.0.x搭建主从</a></li><li><a href=/2022/02/memcached%E9%83%A8%E7%BD%B2/>memcached部署</a></li></ul></div><div class="post-meta meta-tags"><ul class=clearfix><li><a href=/tags/sealos target=_blank>sealos</a></li><li><a href=/tags/kubernetes target=_blank>kubernetes</a></li><li><a href=/tags/deploy target=_blank>deploy</a></li></ul></div></article><div class="post bg-white"><script src=https://utteranc.es/client.js repo=mvpbang/mvpbang.github.io issue-term=title theme=github-light crossorigin=anonymous async></script></div></div><footer id=footer><div>&copy; 2024 <a href=https://blog.mvpbang.com/>mvpbang By mvpbang|本站由Hugo强力驱动, 主题移植自maupassant</a></div><br></footer><script type=text/javascript>window.MathJax={tex2jax:{inlineMath:[["$","$"]],processEscapes:!0}}</script><script src='//cdn.bootcdn.net/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML' async></script><a id=rocket href=#top></a><script type=text/javascript src='/js/totop.js?v=0.0.0' async></script><script async src="https://www.googletagmanager.com/gtag/js?id=G-QTYKS76822"></script><script>var dnt,doNotTrack=!1;if(!1&&(dnt=navigator.doNotTrack||window.doNotTrack||navigator.msDoNotTrack,doNotTrack=dnt=="1"||dnt=="yes"),!doNotTrack){window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag("js",new Date),gtag("config","G-QTYKS76822")}</script><style type=text/css>div.highlight{position:relative;margin:1em 0}.copy-code{display:none;position:absolute;top:4px;right:4px;color:rgba(255,255,255,.8);background:rgba(78,78,78,.8);border-radius:var(--radius);padding:0 5px;font:inherit;user-select:none;cursor:pointer;border:0;--radius:8px}div.highlight:hover .copy-code,pre:hover .copy-code{display:block}</style><script>document.querySelectorAll("pre > code").forEach(e=>{const n=e.parentNode.parentNode,t=document.createElement("button");t.classList.add("copy-code"),t.innerHTML="copy";function s(){t.innerHTML="copied!",setTimeout(()=>{t.innerHTML="copy"},2e3)}t.addEventListener("click",t=>{if("clipboard"in navigator){navigator.clipboard.writeText(e.textContent),s();return}const n=document.createRange();n.selectNodeContents(e);const o=window.getSelection();o.removeAllRanges(),o.addRange(n);try{document.execCommand("copy"),s()}catch{}o.removeRange(n)}),n.classList.contains("highlight")?n.appendChild(t):n.parentNode.firstChild==n||(e.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName=="TABLE"?e.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(t):e.parentNode.appendChild(t))})</script><script type=text/javascript src=//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js async></script><script src=/js/douban.js></script></div><div id=secondary><section class=widget><form id=search action=https://blog.mvpbang.com/search method=get accept-charset=utf-8 target=_blank _lpchecked=1><input type=text name=q maxlength=20 placeholder=Search>
<input type=hidden name=sitesearch value=https://blog.mvpbang.com/>
<button type=submit class="submit icon-search"></button></form></section><section class=widget><h3 class=widget-title>最近文章</h3><ul class=widget-list><li><a href=https://blog.mvpbang.com/2024/10/ds920-%E7%A7%BB%E9%99%A4ssd%E7%BC%93%E5%AD%98/ title=ds920+移除ssd缓存 target=_blank>ds920+移除ssd缓存</a></li><li><a href=https://blog.mvpbang.com/2024/10/mac%E5%A6%82%E4%BD%95%E5%88%87%E6%8D%A2%E4%B8%8B%E4%B8%80%E5%BC%A0%E5%9B%BE%E7%89%87/ title=mac如何切换下一张图片 target=_blank>mac如何切换下一张图片</a></li><li><a href=https://blog.mvpbang.com/2024/10/calico%E5%8E%9F%E7%90%86/ title=calico原理 target=_blank>calico原理</a></li><li><a href=https://blog.mvpbang.com/2024/09/calico-node-not-ready/ title="calico-node not ready" target=_blank>calico-node not ready</a></li><li><a href=https://blog.mvpbang.com/2024/09/genspark-autopilot-agent/ title=genspark-autopilot-agent target=_blank>genspark-autopilot-agent</a></li><li><a href=https://blog.mvpbang.com/2024/09/ssh%E4%B9%8Bconfig%E5%AF%86%E9%92%A5%E8%BF%9C%E7%A8%8B%E7%99%BB%E9%99%86/ title=ssh之config密钥远程登陆 target=_blank>ssh之config密钥远程登陆</a></li><li><a href=https://blog.mvpbang.com/2024/09/mac%E6%89%93%E5%BC%80%E4%BB%BB%E4%BD%95%E6%BA%90-%E5%B0%8F%E5%B7%A5%E5%85%B7/ title=mac打开任何源-小工具 target=_blank>mac打开任何源-小工具</a></li><li><a href=https://blog.mvpbang.com/2024/09/mac%E4%B8%8Bdmg%E8%A7%A3%E5%8E%8B/ title=mac下dmg解压 target=_blank>mac下dmg解压</a></li><li><a href=https://blog.mvpbang.com/2024/08/%E5%9F%BA%E4%BA%8Edockerfile%E6%9E%84%E5%BB%BAcentos8-ruby-3.2/ title=基于dockerfile构建centos8-ruby-3.2 target=_blank>基于dockerfile构建centos8-ruby-3.2</a></li><li><a href=https://blog.mvpbang.com/2024/08/yum%E5%AE%89%E8%A3%85%E6%8F%90%E7%A4%BAinferior-architecture%E5%BC%82%E5%B8%B8/ title=yum安装提示inferior-architecture异常 target=_blank>yum安装提示inferior-architecture异常</a></li></ul></section><section class=widget><h3 class=widget-title><a href=/categories/>分类</a></h3><ul class=widget-list><li><a href=https://blog.mvpbang.com/categories/autofs/>Autofs (1)</a></li><li><a href=https://blog.mvpbang.com/categories/bash/>Bash (3)</a></li><li><a href=https://blog.mvpbang.com/categories/centos/>Centos (19)</a></li><li><a href=https://blog.mvpbang.com/categories/cgroup/>Cgroup (1)</a></li><li><a href=https://blog.mvpbang.com/categories/chrome/>Chrome (1)</a></li><li><a href=https://blog.mvpbang.com/categories/cloud/>Cloud (1)</a></li><li><a href=https://blog.mvpbang.com/categories/cni/>Cni (1)</a></li><li><a href=https://blog.mvpbang.com/categories/comic/>Comic (1)</a></li><li><a href=https://blog.mvpbang.com/categories/command/>Command (21)</a></li><li><a href=https://blog.mvpbang.com/categories/container/>Container (1)</a></li><li><a href=https://blog.mvpbang.com/categories/crontab/>Crontab (1)</a></li><li><a href=https://blog.mvpbang.com/categories/datetime/>Datetime (1)</a></li><li><a href=https://blog.mvpbang.com/categories/dhcp/>Dhcp (1)</a></li><li><a href=https://blog.mvpbang.com/categories/disk/>Disk (1)</a></li><li><a href=https://blog.mvpbang.com/categories/dns/>Dns (1)</a></li><li><a href=https://blog.mvpbang.com/categories/docker/>Docker (10)</a></li><li><a href=https://blog.mvpbang.com/categories/driver/>Driver (1)</a></li><li><a href=https://blog.mvpbang.com/categories/eclipse/>Eclipse (1)</a></li><li><a href=https://blog.mvpbang.com/categories/edge/>Edge (2)</a></li><li><a href=https://blog.mvpbang.com/categories/edit/>Edit (2)</a></li><li><a href=https://blog.mvpbang.com/categories/elasticsearch/>Elasticsearch (1)</a></li><li><a href=https://blog.mvpbang.com/categories/error/>Error (3)</a></li><li><a href=https://blog.mvpbang.com/categories/front/>Front (1)</a></li><li><a href=https://blog.mvpbang.com/categories/ftp/>Ftp (1)</a></li><li><a href=https://blog.mvpbang.com/categories/game/>Game (1)</a></li><li><a href=https://blog.mvpbang.com/categories/git/>Git (7)</a></li><li><a href=https://blog.mvpbang.com/categories/github/>Github (3)</a></li><li><a href=https://blog.mvpbang.com/categories/glibc/>Glibc (2)</a></li><li><a href=https://blog.mvpbang.com/categories/go/>Go (2)</a></li><li><a href=https://blog.mvpbang.com/categories/google/>Google (2)</a></li><li><a href=https://blog.mvpbang.com/categories/harbor/>Harbor (2)</a></li><li><a href=https://blog.mvpbang.com/categories/host/>Host (1)</a></li><li><a href=https://blog.mvpbang.com/categories/http/>Http (1)</a></li><li><a href=https://blog.mvpbang.com/categories/huawei/>Huawei (1)</a></li><li><a href=https://blog.mvpbang.com/categories/hugo/>Hugo (15)</a></li><li><a href=https://blog.mvpbang.com/categories/indexnow/>Indexnow (2)</a></li><li><a href=https://blog.mvpbang.com/categories/iphone/>Iphone (1)</a></li><li><a href=https://blog.mvpbang.com/categories/java/>Java (2)</a></li><li><a href=https://blog.mvpbang.com/categories/jdk/>Jdk (1)</a></li><li><a href=https://blog.mvpbang.com/categories/jenkins/>Jenkins (2)</a></li><li><a href=https://blog.mvpbang.com/categories/jumpserver/>Jumpserver (1)</a></li><li><a href=https://blog.mvpbang.com/categories/kibana/>Kibana (1)</a></li><li><a href=https://blog.mvpbang.com/categories/kubernetes/>Kubernetes (5)</a></li><li><a href=https://blog.mvpbang.com/categories/language/>Language (1)</a></li><li><a href=https://blog.mvpbang.com/categories/linux/>Linux (19)</a></li><li><a href=https://blog.mvpbang.com/categories/llm/>Llm (2)</a></li><li><a href=https://blog.mvpbang.com/categories/ln/>Ln (1)</a></li><li><a href=https://blog.mvpbang.com/categories/log/>Log (3)</a></li><li><a href=https://blog.mvpbang.com/categories/login/>Login (1)</a></li><li><a href=https://blog.mvpbang.com/categories/logstash/>Logstash (1)</a></li><li><a href=https://blog.mvpbang.com/categories/mac/>Mac (14)</a></li><li><a href=https://blog.mvpbang.com/categories/mail/>Mail (2)</a></li><li><a href=https://blog.mvpbang.com/categories/mariadb/>Mariadb (1)</a></li><li><a href=https://blog.mvpbang.com/categories/memcached/>Memcached (2)</a></li><li><a href=https://blog.mvpbang.com/categories/memory/>Memory (4)</a></li><li><a href=https://blog.mvpbang.com/categories/mirror/>Mirror (2)</a></li><li><a href=https://blog.mvpbang.com/categories/monitor/>Monitor (1)</a></li><li><a href=https://blog.mvpbang.com/categories/music/>Music (1)</a></li><li><a href=https://blog.mvpbang.com/categories/mysql/>Mysql (23)</a></li><li><a href=https://blog.mvpbang.com/categories/nas/>Nas (1)</a></li><li><a href=https://blog.mvpbang.com/categories/navicat/>Navicat (1)</a></li><li><a href=https://blog.mvpbang.com/categories/network/>Network (8)</a></li><li><a href=https://blog.mvpbang.com/categories/nfs/>Nfs (4)</a></li><li><a href=https://blog.mvpbang.com/categories/nginx/>Nginx (6)</a></li><li><a href=https://blog.mvpbang.com/categories/ntp/>Ntp (1)</a></li><li><a href=https://blog.mvpbang.com/categories/oacle/>Oacle (1)</a></li><li><a href=https://blog.mvpbang.com/categories/opensuse/>Opensuse (2)</a></li><li><a href=https://blog.mvpbang.com/categories/oracle/>Oracle (12)</a></li><li><a href=https://blog.mvpbang.com/categories/oracle11g/>Oracle11g (3)</a></li><li><a href=https://blog.mvpbang.com/categories/passwd/>Passwd (1)</a></li><li><a href=https://blog.mvpbang.com/categories/password/>Password (1)</a></li><li><a href=https://blog.mvpbang.com/categories/php/>Php (1)</a></li><li><a href=https://blog.mvpbang.com/categories/plsql/>Plsql (1)</a></li><li><a href=https://blog.mvpbang.com/categories/postman/>Postman (1)</a></li><li><a href=https://blog.mvpbang.com/categories/process/>Process (1)</a></li><li><a href=https://blog.mvpbang.com/categories/proxy/>Proxy (1)</a></li><li><a href=https://blog.mvpbang.com/categories/python/>Python (3)</a></li><li><a href=https://blog.mvpbang.com/categories/redhat/>Redhat (3)</a></li><li><a href=https://blog.mvpbang.com/categories/redis/>Redis (9)</a></li><li><a href=https://blog.mvpbang.com/categories/rpm/>Rpm (1)</a></li><li><a href=https://blog.mvpbang.com/categories/rsync/>Rsync (1)</a></li><li><a href=https://blog.mvpbang.com/categories/ruby/>Ruby (2)</a></li><li><a href=https://blog.mvpbang.com/categories/samba/>Samba (2)</a></li><li><a href=https://blog.mvpbang.com/categories/sealos/>Sealos (4)</a></li><li><a href=https://blog.mvpbang.com/categories/secrity/>Secrity (1)</a></li><li><a href=https://blog.mvpbang.com/categories/securecrt/>Securecrt (1)</a></li><li><a href=https://blog.mvpbang.com/categories/seeddms/>Seeddms (2)</a></li><li><a href=https://blog.mvpbang.com/categories/seo/>Seo (1)</a></li><li><a href=https://blog.mvpbang.com/categories/session/>Session (1)</a></li><li><a href=https://blog.mvpbang.com/categories/sftpgo/>Sftpgo (1)</a></li><li><a href=https://blog.mvpbang.com/categories/shell/>Shell (9)</a></li><li><a href=https://blog.mvpbang.com/categories/snip/>Snip (1)</a></li><li><a href=https://blog.mvpbang.com/categories/soft/>Soft (1)</a></li><li><a href=https://blog.mvpbang.com/categories/sonarqube/>Sonarqube (1)</a></li><li><a href=https://blog.mvpbang.com/categories/sqlite/>Sqlite (1)</a></li><li><a href=https://blog.mvpbang.com/categories/sre/>Sre (1)</a></li><li><a href=https://blog.mvpbang.com/categories/ssh/>Ssh (9)</a></li><li><a href=https://blog.mvpbang.com/categories/sshd/>Sshd (3)</a></li><li><a href=https://blog.mvpbang.com/categories/storage/>Storage (1)</a></li><li><a href=https://blog.mvpbang.com/categories/study/>Study (4)</a></li><li><a href=https://blog.mvpbang.com/categories/sublime/>Sublime (1)</a></li><li><a href=https://blog.mvpbang.com/categories/sudo/>Sudo (1)</a></li><li><a href=https://blog.mvpbang.com/categories/svn/>Svn (1)</a></li><li><a href=https://blog.mvpbang.com/categories/swap/>Swap (1)</a></li><li><a href=https://blog.mvpbang.com/categories/synology/>Synology (2)</a></li><li><a href=https://blog.mvpbang.com/categories/tar/>Tar (1)</a></li><li><a href=https://blog.mvpbang.com/categories/teleport/>Teleport (1)</a></li><li><a href=https://blog.mvpbang.com/categories/telnet/>Telnet (1)</a></li><li><a href=https://blog.mvpbang.com/categories/terminal/>Terminal (4)</a></li><li><a href=https://blog.mvpbang.com/categories/tftp/>Tftp (1)</a></li><li><a href=https://blog.mvpbang.com/categories/tomcat/>Tomcat (2)</a></li><li><a href=https://blog.mvpbang.com/categories/tool/>Tool (1)</a></li><li><a href=https://blog.mvpbang.com/categories/tools/>Tools (2)</a></li><li><a href=https://blog.mvpbang.com/categories/ubuntu/>Ubuntu (4)</a></li><li><a href=https://blog.mvpbang.com/categories/vagrant/>Vagrant (3)</a></li><li><a href=https://blog.mvpbang.com/categories/vbox/>Vbox (1)</a></li><li><a href=https://blog.mvpbang.com/categories/vmware/>Vmware (4)</a></li><li><a href=https://blog.mvpbang.com/categories/vnc/>Vnc (2)</a></li><li><a href=https://blog.mvpbang.com/categories/vscode/>Vscode (2)</a></li><li><a href=https://blog.mvpbang.com/categories/vsftpd/>Vsftpd (2)</a></li><li><a href=https://blog.mvpbang.com/categories/webbench/>Webbench (1)</a></li><li><a href=https://blog.mvpbang.com/categories/weblogic/>Weblogic (5)</a></li><li><a href=https://blog.mvpbang.com/categories/window/>Window (17)</a></li><li><a href=https://blog.mvpbang.com/categories/window11/>Window11 (1)</a></li><li><a href=https://blog.mvpbang.com/categories/xdmcp/>Xdmcp (1)</a></li><li><a href=https://blog.mvpbang.com/categories/xmanager/>Xmanager (1)</a></li><li><a href=https://blog.mvpbang.com/categories/yum/>Yum (8)</a></li><li><a href=https://blog.mvpbang.com/categories/zip/>Zip (1)</a></li><li><a href=https://blog.mvpbang.com/categories/zookeeper/>Zookeeper (1)</a></li></ul></section><section class=widget><h3 class=widget-title><a href=/tags/>标签</a></h3><div class=tagcloud><a href=https://blog.mvpbang.com/tags/7z/>7z</a>
<a href=https://blog.mvpbang.com/tags/agent/>Agent</a>
<a href=https://blog.mvpbang.com/tags/aliyun/>Aliyun</a>
<a href=https://blog.mvpbang.com/tags/android/>Android</a>
<a href=https://blog.mvpbang.com/tags/app/>App</a>
<a href=https://blog.mvpbang.com/tags/apt/>Apt</a>
<a href=https://blog.mvpbang.com/tags/autofs/>Autofs</a>
<a href=https://blog.mvpbang.com/tags/bash/>Bash</a>
<a href=https://blog.mvpbang.com/tags/bing/>Bing</a>
<a href=https://blog.mvpbang.com/tags/bootcamp/>Bootcamp</a>
<a href=https://blog.mvpbang.com/tags/cache/>Cache</a>
<a href=https://blog.mvpbang.com/tags/calico/>Calico</a>
<a href=https://blog.mvpbang.com/tags/cdn/>Cdn</a>
<a href=https://blog.mvpbang.com/tags/centos/>Centos</a>
<a href=https://blog.mvpbang.com/tags/centos6/>Centos6</a>
<a href=https://blog.mvpbang.com/tags/centos7/>Centos7</a>
<a href=https://blog.mvpbang.com/tags/centos8/>Centos8</a>
<a href=https://blog.mvpbang.com/tags/cgroup/>Cgroup</a>
<a href=https://blog.mvpbang.com/tags/char/>Char</a>
<a href=https://blog.mvpbang.com/tags/charset/>Charset</a>
<a href=https://blog.mvpbang.com/tags/chatgpt/>Chatgpt</a>
<a href=https://blog.mvpbang.com/tags/chrome/>Chrome</a>
<a href=https://blog.mvpbang.com/tags/clone/>Clone</a>
<a href=https://blog.mvpbang.com/tags/cloudflare/>Cloudflare</a>
<a href=https://blog.mvpbang.com/tags/cmd/>Cmd</a>
<a href=https://blog.mvpbang.com/tags/comic/>Comic</a>
<a href=https://blog.mvpbang.com/tags/command/>Command</a>
<a href=https://blog.mvpbang.com/tags/crontab/>Crontab</a>
<a href=https://blog.mvpbang.com/tags/curl/>Curl</a>
<a href=https://blog.mvpbang.com/tags/date/>Date</a>
<a href=https://blog.mvpbang.com/tags/datetime/>Datetime</a>
<a href=https://blog.mvpbang.com/tags/deploy/>Deploy</a>
<a href=https://blog.mvpbang.com/tags/desktop/>Desktop</a>
<a href=https://blog.mvpbang.com/tags/dhcp/>Dhcp</a>
<a href=https://blog.mvpbang.com/tags/disk/>Disk</a>
<a href=https://blog.mvpbang.com/tags/dmg/>Dmg</a>
<a href=https://blog.mvpbang.com/tags/dnf/>Dnf</a>
<a href=https://blog.mvpbang.com/tags/dns/>Dns</a>
<a href=https://blog.mvpbang.com/tags/doc/>Doc</a>
<a href=https://blog.mvpbang.com/tags/docker/>Docker</a>
<a href=https://blog.mvpbang.com/tags/docker-compose/>Docker-Compose</a>
<a href=https://blog.mvpbang.com/tags/dockerfile/>Dockerfile</a>
<a href=https://blog.mvpbang.com/tags/download/>Download</a>
<a href=https://blog.mvpbang.com/tags/driver/>Driver</a>
<a href=https://blog.mvpbang.com/tags/ds920+/>Ds920+</a>
<a href=https://blog.mvpbang.com/tags/du/>Du</a>
<a href=https://blog.mvpbang.com/tags/edge/>Edge</a>
<a href=https://blog.mvpbang.com/tags/editplus/>Editplus</a>
<a href=https://blog.mvpbang.com/tags/error/>Error</a>
<a href=https://blog.mvpbang.com/tags/eth0/>Eth0</a>
<a href=https://blog.mvpbang.com/tags/file/>File</a>
<a href=https://blog.mvpbang.com/tags/free/>Free</a>
<a href=https://blog.mvpbang.com/tags/front/>Front</a>
<a href=https://blog.mvpbang.com/tags/ftp/>Ftp</a>
<a href=https://blog.mvpbang.com/tags/ghcr/>Ghcr</a>
<a href=https://blog.mvpbang.com/tags/git/>Git</a>
<a href=https://blog.mvpbang.com/tags/github/>Github</a>
<a href=https://blog.mvpbang.com/tags/glibc/>Glibc</a>
<a href=https://blog.mvpbang.com/tags/go/>Go</a>
<a href=https://blog.mvpbang.com/tags/goland/>Goland</a>
<a href=https://blog.mvpbang.com/tags/google/>Google</a>
<a href=https://blog.mvpbang.com/tags/goproxy/>Goproxy</a>
<a href=https://blog.mvpbang.com/tags/grep/>Grep</a>
<a href=https://blog.mvpbang.com/tags/harbor/>Harbor</a>
<a href=https://blog.mvpbang.com/tags/hosts/>Hosts</a>
<a href=https://blog.mvpbang.com/tags/http/>Http</a>
<a href=https://blog.mvpbang.com/tags/huawei/>Huawei</a>
<a href=https://blog.mvpbang.com/tags/hub/>Hub</a>
<a href=https://blog.mvpbang.com/tags/hugo/>Hugo</a>
<a href=https://blog.mvpbang.com/tags/image/>Image</a>
<a href=https://blog.mvpbang.com/tags/indexnow/>Indexnow</a>
<a href=https://blog.mvpbang.com/tags/iphone/>Iphone</a>
<a href=https://blog.mvpbang.com/tags/iso/>Iso</a>
<a href=https://blog.mvpbang.com/tags/jdk/>Jdk</a>
<a href=https://blog.mvpbang.com/tags/jenkins/>Jenkins</a>
<a href=https://blog.mvpbang.com/tags/jetbran/>Jetbran</a>
<a href=https://blog.mvpbang.com/tags/jumpserver/>Jumpserver</a>
<a href=https://blog.mvpbang.com/tags/kernel/>Kernel</a>
<a href=https://blog.mvpbang.com/tags/key/>Key</a>
<a href=https://blog.mvpbang.com/tags/kibana/>Kibana</a>
<a href=https://blog.mvpbang.com/tags/kill/>Kill</a>
<a href=https://blog.mvpbang.com/tags/kube-proxy/>Kube-Proxy</a>
<a href=https://blog.mvpbang.com/tags/kubeadm/>Kubeadm</a>
<a href=https://blog.mvpbang.com/tags/kubectl/>Kubectl</a>
<a href=https://blog.mvpbang.com/tags/kubernetes/>Kubernetes</a>
<a href=https://blog.mvpbang.com/tags/language/>Language</a>
<a href=https://blog.mvpbang.com/tags/linux/>Linux</a>
<a href=https://blog.mvpbang.com/tags/ln/>Ln</a>
<a href=https://blog.mvpbang.com/tags/log/>Log</a>
<a href=https://blog.mvpbang.com/tags/log4j/>Log4j</a>
<a href=https://blog.mvpbang.com/tags/login/>Login</a>
<a href=https://blog.mvpbang.com/tags/logstash/>Logstash</a>
<a href=https://blog.mvpbang.com/tags/lol/>Lol</a>
<a href=https://blog.mvpbang.com/tags/ls/>Ls</a>
<a href=https://blog.mvpbang.com/tags/lvm/>Lvm</a>
<a href=https://blog.mvpbang.com/tags/mac/>Mac</a>
<a href=https://blog.mvpbang.com/tags/mail/>Mail</a>
<a href=https://blog.mvpbang.com/tags/mariadb/>Mariadb</a>
<a href=https://blog.mvpbang.com/tags/memcached/>Memcached</a>
<a href=https://blog.mvpbang.com/tags/memory/>Memory</a>
<a href=https://blog.mvpbang.com/tags/mirror/>Mirror</a>
<a href=https://blog.mvpbang.com/tags/monitor/>Monitor</a>
<a href=https://blog.mvpbang.com/tags/mount/>Mount</a>
<a href=https://blog.mvpbang.com/tags/music/>Music</a>
<a href=https://blog.mvpbang.com/tags/mysql/>Mysql</a>
<a href=https://blog.mvpbang.com/tags/mysql5.1/>Mysql5.1</a>
<a href=https://blog.mvpbang.com/tags/mysql5.6/>Mysql5.6</a>
<a href=https://blog.mvpbang.com/tags/navicat/>Navicat</a>
<a href=https://blog.mvpbang.com/tags/network/>Network</a>
<a href=https://blog.mvpbang.com/tags/nfs/>Nfs</a>
<a href=https://blog.mvpbang.com/tags/nginx/>Nginx</a>
<a href=https://blog.mvpbang.com/tags/notepad++/>Notepad++</a>
<a href=https://blog.mvpbang.com/tags/ntp/>Ntp</a>
<a href=https://blog.mvpbang.com/tags/openeuler/>Openeuler</a>
<a href=https://blog.mvpbang.com/tags/openkylin/>Openkylin</a>
<a href=https://blog.mvpbang.com/tags/opensuse/>Opensuse</a>
<a href=https://blog.mvpbang.com/tags/oracle/>Oracle</a>
<a href=https://blog.mvpbang.com/tags/oracle11g/>Oracle11g</a>
<a href=https://blog.mvpbang.com/tags/os/>Os</a>
<a href=https://blog.mvpbang.com/tags/passwd/>Passwd</a>
<a href=https://blog.mvpbang.com/tags/password/>Password</a>
<a href=https://blog.mvpbang.com/tags/pdf/>Pdf</a>
<a href=https://blog.mvpbang.com/tags/php/>Php</a>
<a href=https://blog.mvpbang.com/tags/pip/>Pip</a>
<a href=https://blog.mvpbang.com/tags/pkg/>Pkg</a>
<a href=https://blog.mvpbang.com/tags/plsql/>Plsql</a>
<a href=https://blog.mvpbang.com/tags/postman/>Postman</a>
<a href=https://blog.mvpbang.com/tags/process/>Process</a>
<a href=https://blog.mvpbang.com/tags/progress/>Progress</a>
<a href=https://blog.mvpbang.com/tags/ps/>Ps</a>
<a href=https://blog.mvpbang.com/tags/pycharm/>Pycharm</a>
<a href=https://blog.mvpbang.com/tags/python/>Python</a>
<a href=https://blog.mvpbang.com/tags/python2.7/>Python2.7</a>
<a href=https://blog.mvpbang.com/tags/raid/>Raid</a>
<a href=https://blog.mvpbang.com/tags/rancher/>Rancher</a>
<a href=https://blog.mvpbang.com/tags/ranhcer/>Ranhcer</a>
<a href=https://blog.mvpbang.com/tags/rar/>Rar</a>
<a href=https://blog.mvpbang.com/tags/redhat/>Redhat</a>
<a href=https://blog.mvpbang.com/tags/redis/>Redis</a>
<a href=https://blog.mvpbang.com/tags/rm/>Rm</a>
<a href=https://blog.mvpbang.com/tags/rpm/>Rpm</a>
<a href=https://blog.mvpbang.com/tags/rsync/>Rsync</a>
<a href=https://blog.mvpbang.com/tags/rsyslog/>Rsyslog</a>
<a href=https://blog.mvpbang.com/tags/ruby/>Ruby</a>
<a href=https://blog.mvpbang.com/tags/samba/>Samba</a>
<a href=https://blog.mvpbang.com/tags/screen/>Screen</a>
<a href=https://blog.mvpbang.com/tags/sealos/>Sealos</a>
<a href=https://blog.mvpbang.com/tags/securecrt/>Securecrt</a>
<a href=https://blog.mvpbang.com/tags/security/>Security</a>
<a href=https://blog.mvpbang.com/tags/seeddms/>Seeddms</a>
<a href=https://blog.mvpbang.com/tags/seo/>Seo</a>
<a href=https://blog.mvpbang.com/tags/session/>Session</a>
<a href=https://blog.mvpbang.com/tags/sftp/>Sftp</a>
<a href=https://blog.mvpbang.com/tags/sftpgo/>Sftpgo</a>
<a href=https://blog.mvpbang.com/tags/sh/>Sh</a>
<a href=https://blog.mvpbang.com/tags/shell/>Shell</a>
<a href=https://blog.mvpbang.com/tags/soft/>Soft</a>
<a href=https://blog.mvpbang.com/tags/sonarqube/>Sonarqube</a>
<a href=https://blog.mvpbang.com/tags/spring/>Spring</a>
<a href=https://blog.mvpbang.com/tags/sql/>Sql</a>
<a href=https://blog.mvpbang.com/tags/sqlite/>Sqlite</a>
<a href=https://blog.mvpbang.com/tags/sqlplus/>Sqlplus</a>
<a href=https://blog.mvpbang.com/tags/sre/>Sre</a>
<a href=https://blog.mvpbang.com/tags/ssd/>Ssd</a>
<a href=https://blog.mvpbang.com/tags/ssh/>Ssh</a>
<a href=https://blog.mvpbang.com/tags/sshd/>Sshd</a>
<a href=https://blog.mvpbang.com/tags/stats/>Stats</a>
<a href=https://blog.mvpbang.com/tags/study/>Study</a>
<a href=https://blog.mvpbang.com/tags/sublime/>Sublime</a>
<a href=https://blog.mvpbang.com/tags/sudo/>Sudo</a>
<a href=https://blog.mvpbang.com/tags/svn/>Svn</a>
<a href=https://blog.mvpbang.com/tags/swap/>Swap</a>
<a href=https://blog.mvpbang.com/tags/sync/>Sync</a>
<a href=https://blog.mvpbang.com/tags/synology/>Synology</a>
<a href=https://blog.mvpbang.com/tags/tar/>Tar</a>
<a href=https://blog.mvpbang.com/tags/telegram/>Telegram</a>
<a href=https://blog.mvpbang.com/tags/teleport/>Teleport</a>
<a href=https://blog.mvpbang.com/tags/telnet/>Telnet</a>
<a href=https://blog.mvpbang.com/tags/tengine/>Tengine</a>
<a href=https://blog.mvpbang.com/tags/terminal/>Terminal</a>
<a href=https://blog.mvpbang.com/tags/tftp/>Tftp</a>
<a href=https://blog.mvpbang.com/tags/tldr/>Tldr</a>
<a href=https://blog.mvpbang.com/tags/tomcat/>Tomcat</a>
<a href=https://blog.mvpbang.com/tags/top/>Top</a>
<a href=https://blog.mvpbang.com/tags/traffic/>Traffic</a>
<a href=https://blog.mvpbang.com/tags/ubuntu/>Ubuntu</a>
<a href=https://blog.mvpbang.com/tags/ubuntu16/>Ubuntu16</a>
<a href=https://blog.mvpbang.com/tags/uid/>Uid</a>
<a href=https://blog.mvpbang.com/tags/umask/>Umask</a>
<a href=https://blog.mvpbang.com/tags/up/>Up</a>
<a href=https://blog.mvpbang.com/tags/upgrade/>Upgrade</a>
<a href=https://blog.mvpbang.com/tags/v2ray/>V2ray</a>
<a href=https://blog.mvpbang.com/tags/vagrant/>Vagrant</a>
<a href=https://blog.mvpbang.com/tags/vbox/>Vbox</a>
<a href=https://blog.mvpbang.com/tags/video/>Video</a>
<a href=https://blog.mvpbang.com/tags/virtual/>Virtual</a>
<a href=https://blog.mvpbang.com/tags/vmware/>Vmware</a>
<a href=https://blog.mvpbang.com/tags/vnc/>Vnc</a>
<a href=https://blog.mvpbang.com/tags/vscode/>Vscode</a>
<a href=https://blog.mvpbang.com/tags/vsftpd/>Vsftpd</a>
<a href=https://blog.mvpbang.com/tags/webbench/>Webbench</a>
<a href=https://blog.mvpbang.com/tags/weblogic/>Weblogic</a>
<a href=https://blog.mvpbang.com/tags/webmin/>Webmin</a>
<a href=https://blog.mvpbang.com/tags/window/>Window</a>
<a href=https://blog.mvpbang.com/tags/window11/>Window11</a>
<a href=https://blog.mvpbang.com/tags/wsl/>Wsl</a>
<a href=https://blog.mvpbang.com/tags/x-snip/>X-Snip</a>
<a href=https://blog.mvpbang.com/tags/xdmcp/>Xdmcp</a>
<a href=https://blog.mvpbang.com/tags/xfs/>Xfs</a>
<a href=https://blog.mvpbang.com/tags/xmanager/>Xmanager</a>
<a href=https://blog.mvpbang.com/tags/yum/>Yum</a>
<a href=https://blog.mvpbang.com/tags/zip/>Zip</a>
<a href=https://blog.mvpbang.com/tags/zookeeper/>Zookeeper</a></div></section><section class=widget><h3 class=widget-title>友情链接</h3><ul class=widget-list><li><a target=_blank href=https://blog.frognew.com/ title=青蛙小白>青蛙小白</a></li><li><a target=_blank href=https://henudev.github.io/ title=秦小山的博客>秦鸡儿</a></li><li><a target=_blank href=http://www.dayanzai.me/ title=大眼仔>大眼仔</a></li></ul></section><section class=widget><h3 class=widget-title>其它</h3><ul class=widget-list><li><a href=https://blog.mvpbang.com/index.xml>文章 RSS</a></li></ul></section></div></div></div></div></body></html>